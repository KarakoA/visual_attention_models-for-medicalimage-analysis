{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Depdencies & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (1.5.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: torchviz in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (1.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (4.46.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: tensorboard_logger in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (0.1.0)\n",
      "Requirement already satisfied: future in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from torchvision) (7.1.2)\n",
      "Requirement already satisfied: graphviz in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from torchviz) (0.14)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from scikit-image) (2.3)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from scikit-image) (2020.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from scikit-image) (2.8.0)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from tensorboard_logger) (1.14.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from tensorboard_logger) (3.12.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages (from protobuf->tensorboard_logger) (46.1.3.post20200330)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchviz matplotlib numpy tqdm scikit-image tensorboard_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import Dataset\n",
    "from torchviz import make_dot\n",
    "\n",
    "import skimage.measure\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import unittest\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetName(Enum):\n",
    "    MNIST = 1\n",
    "    AUGMENTED = 2\n",
    "    TRANSFORMED = 3\n",
    "    AUGMENTED_MEDICAL = 4\n",
    "    CONSTRUCTED = 5\n",
    "    AUGMENTED_MEDICAL_2 = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        # glimpse network params\n",
    "        self.patch_size      = 8         # size of extracted patch at highest res\n",
    "        self.glimpse_scale   = 8         # scale of successive patches\n",
    "        self.num_patches     = 2         # Num of downscaled patches per glimpse\n",
    "        self.loc_hidden      = 128       # hidden size of loc fc layer\n",
    "        self.glimpse_hidden  = 128       # hidden size of glimpse fc\n",
    "\n",
    "        # core network params\n",
    "        self.num_glimpses    = 10         # Num of glimpses, i.e. BPTT iterations\n",
    "        self.hidden_size     = 256       # hidden size of rnn\n",
    "\n",
    "        # reinforce params\n",
    "        self.std             = 0.05      # gaussian policy standard deviation\n",
    "        self.M               = 1         # Monte Carlo sampling for valid and test sets\n",
    "\n",
    "        # ETC params\n",
    "        self.valid_size      = 0.1       # Proportion of training set used for validation\n",
    "        self.batch_size      = 128       # Num of images in each batch of data\n",
    "        self.num_workers     = 4         # Num of subprocesses to use for data loading\n",
    "        self.shuffle         = True      # Whether to shuffle the train and valid indices\n",
    "        self.show_sample     = False     # Whether to visualize a sample grid of the data\n",
    "\n",
    "        # training params\n",
    "        self.is_train        = True      # Whether to train(true) or test the model\n",
    "        self.weight_decay    = 1e-5      # Weight decay for regularization\n",
    "        self.momentum        = 0.5       # Nesterov momentum value\n",
    "        self.epochs          = 500       # Num of epochs to train for\n",
    "        self.init_lr         = 3e-4      # Initial learning rate value\n",
    "        self.lr_patience     = 20        # Number of epochs to wait before reducing lr\n",
    "        self.train_patience  = 150       # Number of epochs to wait before stopping train\n",
    "\n",
    "        # other params\n",
    "        self.resume          = False     # Whether to resume training from checkpoint\n",
    "        self.use_gpu         = True      # Whether to run on the GPU\n",
    "        self.best            = True      # Load best model or most recent for testing\n",
    "        self.random_seed     = 1         # Seed to ensure reproducibility\n",
    "        self.data_dir        = \"./data\"  # Directory in which data is stored\n",
    "        self.ckpt_dir        = \"./ckpt\"  # Directory in which to save model checkpoints\n",
    "        self.logs_dir        = \"./logs/\" # Directory in which Tensorboard logs wil be stored\n",
    "        self.use_tensorboard = False     # Whether to use tensorboard for visualization\n",
    "        self.print_freq      = 100       # How frequently to print training details\n",
    "        self.plot_freq       = 1         # How frequently to plot glimpses\n",
    "        self.dataset         = DatasetName.CONSTRUCTED\n",
    "        self.model_name      = \"ram_{}_{}x{}_{}\".format(\n",
    "            self.num_glimpses,\n",
    "            self.patch_size,\n",
    "            self.patch_size,\n",
    "            self.glimpse_scale,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for reproducibility\n",
    "torch.manual_seed(global_config.random_seed)\n",
    "np.random.seed(global_config.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstructedDataset(Dataset):\n",
    "    \"\"\"Binary: number of not closed squares\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 train,\n",
    "                 size = 64,\n",
    "                 object_width = 3,\n",
    "                 n_missing = 2,\n",
    "                 n_classes = 4,\n",
    "                 n_circles = 6,\n",
    "                 total_train = 4000,\n",
    "                 total_test = 400):\n",
    "        if train:\n",
    "            np.random.seed(1)\n",
    "        else:\n",
    "            np.random.seed(2)\n",
    "        self.n = total_train if train else total_test\n",
    "        self.__create_data(n_classes, n_circles, size, object_width, n_missing)\n",
    "    \n",
    "    def __create_data(self, n_classes, n_circles, size, object_width, n_missing):\n",
    "        self.labels = []\n",
    "        self.data   = []\n",
    "        \n",
    "        for class_i in range(n_classes):\n",
    "            for _ in range(int(self.n/n_classes)):\n",
    "                image = self.__generate_image(class_i, n_circles, size,object_width,n_missing)\n",
    "                self.data.append(torch.tensor(image))\n",
    "                self.labels.append(class_i)\n",
    "\n",
    "    def __generate_image(self,n_open, n_all, size, object_width, n_missing ):\n",
    "        image = np.zeros((size,size))\n",
    "        # top left x,y positions within bounds\n",
    "        top_lefts = (np.random.rand(n_all, 2) * (size - (object_width+2))).astype(int)\n",
    "        # ensure no overlapping\n",
    "        for top_left in top_lefts:\n",
    "            x_0, y_0 = top_left[0],top_left[1]\n",
    "            # 1 bigger so no overlaps\n",
    "            image[x_0: x_0 + object_width + 2 , y_0:y_0 + object_width + 2 ] += 1\n",
    "        # make sure no overlapping\n",
    "        is_valid = np.all(image <= 1)\n",
    "        if is_valid:\n",
    "            image = np.zeros((size,size)).astype(np.float32)\n",
    "            for i,top_left in enumerate(top_lefts):\n",
    "                x_0, y_0 = top_left[0] +1 ,top_left[1] +1\n",
    "                image[x_0: x_0 + object_width , y_0:y_0 + object_width] = 1\n",
    "                # open it\n",
    "                if  i < n_open:\n",
    "                    pos = (np.random.rand(n_missing, 2) * object_width).astype(int)\n",
    "                    for p in pos:\n",
    "                        image[x_0+p[0],y_0+p[1]] = 0\n",
    "            return image.reshape(1,size,size)\n",
    "        else:\n",
    "            return self.__generate_image(n_open, n_all, size, object_width, n_missing)                \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, uid):\n",
    "        if torch.is_tensor(uid):\n",
    "            uid = uid.tolist()\n",
    "        label = self.labels[uid]\n",
    "        sample = self.data[uid]\n",
    "        \n",
    "        return (sample,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedMedicalMNISTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Augmented mnist meant to mimic whole-slide-images of tumor cells.\n",
    "    9's represent cancer cells. There are 4 different labels, based on the number of 9's:\n",
    "    \n",
    "    zero 9's          - no cancer\n",
    "    one 9             - isolated tumor cell\n",
    "    two 9's           - micro-metastasis \n",
    "    three or more 9's - macro-metastasis\n",
    "    \n",
    "    Each image contains between 3 and 10 cells at random, which may be overlapping.\n",
    "    It consists of 5000 items of each category(total 20.000) for training and 500(2.000) of each for testing\n",
    "    of size 256 x 256. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 root_dir,\n",
    "                 train,\n",
    "                 data_dir = \"MEDNIST\",\n",
    "                 mnist_transform = None,\n",
    "                 transform = None, \n",
    "                 total_train = 20000,\n",
    "                 total_test = 2000,\n",
    "                 n_partitions_test = 1,\n",
    "                 n_partitions_train = 5):\n",
    "        \n",
    "        self.mnist_transform = mnist_transform\n",
    "        self.root_dir = root_dir\n",
    "        self.train = train\n",
    "        self.total = total_train if self.train else total_test\n",
    "        self.n_partitions_test  = n_partitions_test\n",
    "        self.n_partitions_train = n_partitions_train\n",
    "        self.dir = os.path.join(root_dir,data_dir, \"train\" if train else \"test\")\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.__create_dataset_if_needed()\n",
    "                \n",
    "        self.__load_data()\n",
    "        \n",
    "    def __dataset_exists(self):\n",
    "        # mkdir if not exists\n",
    "        os.makedirs(self.dir, exist_ok = True)\n",
    "        len_files = len(os.listdir(self.dir)) \n",
    "        if len_files > 0:\n",
    "            print(\"Data existing, skipping creation.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Dataset missing. Creating...\")\n",
    "        return False\n",
    "            \n",
    "    \n",
    "    def __combine_images(self,images, output_dim):\n",
    "        \"\"\"\n",
    "        Combines the given images into a single image of output_dim size. Combinations are done randomly and \n",
    "        overlapping is possible. Images will always be within bounds completely.\n",
    "        \"\"\"\n",
    "        np_images = np.array(images)\n",
    "        input_dim = np_images.shape[-1]\n",
    "        new_image = np.zeros(shape=(output_dim,output_dim), dtype = np.float32)\n",
    "        for image in np_images:\n",
    "            i, j = np.random.randint(0, output_dim  - input_dim, size = 2)\n",
    "            new_image[i:i+input_dim, j:j+input_dim] = image\n",
    "        return new_image\n",
    "    \n",
    "    def __get_cell_counts(self, items_per_class_count, class_index):\n",
    "        # exclusive\n",
    "        max_items = 11\n",
    "        min_number_of_cells = 3\n",
    "        # 0,1,2,3+ for no tumor cells, isolated tumor cells, \n",
    "        # micro-metastasis and macro-metastasis respectively\n",
    "        num_tumor_cells = class_index if class_index != 3 else np.random.randint(3, max_items) \n",
    "\n",
    "        num_healthy_cells = max_items - num_tumor_cells\n",
    "        if num_healthy_cells + num_tumor_cells < min_number_of_cells:\n",
    "            num_healthy_cells = min_number_of_cells - num_tumor_cells\n",
    "\n",
    "        return (num_tumor_cells, num_healthy_cells)\n",
    "            \n",
    "    def __generate_for_class(self,\n",
    "                                   items,\n",
    "                                   items_per_class_count,\n",
    "                                   class_index,\n",
    "                                   uid,\n",
    "                                   all_tumor_cell_images,\n",
    "                                   all_healthy_cell_images):\n",
    "        for _ in range(items_per_class_count):\n",
    "            num_tumors, num_healthy = self.__get_cell_counts(items_per_class_count, class_index)\n",
    "\n",
    "            healthy_idxs  = np.random.randint(0,len(all_healthy_cell_images), num_healthy)\n",
    "            tumor_idxs    = np.random.randint(0,len(all_tumor_cell_images), num_tumors)\n",
    "\n",
    "            healthy_cells = all_healthy_cell_images[healthy_idxs]\n",
    "            tumor_cells   = all_tumor_cell_images[tumor_idxs]\n",
    "            cells = np.vstack((healthy_cells,tumor_cells))\n",
    "            image = self.__combine_images(cells, 256)\n",
    "            image = np.expand_dims(image, axis = 0)\n",
    "            self.data.append(image)\n",
    "            self.source_images.append(tumor_cells.numpy())\n",
    "            self.labels.append(class_index)\n",
    "            uid += 1\n",
    "        return uid\n",
    "            \n",
    "    def __create_dataset_if_needed(self):\n",
    "        if self.__dataset_exists():\n",
    "            return \n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.source_images = []\n",
    "        \n",
    "        # in how many partitions to split dataset creation\n",
    "        partitions_count = 10\n",
    "        \n",
    "        # number of classes in output (fixed)\n",
    "        num_classes = 4\n",
    "        \n",
    "        mnist = torchvision.datasets.MNIST(root ='./data',\n",
    "                                           train = True,\n",
    "                                           download = True,\n",
    "                                           transform = self.mnist_transform)\n",
    "        \n",
    "        mnist_loader = iter(torch.utils.data.DataLoader(mnist, \n",
    "                                                        batch_size = int(self.total/partitions_count), \n",
    "                                                        shuffle = False, \n",
    "                                                        num_workers = 0))\n",
    "        uid = 0\n",
    "        batch, mnist_labels = mnist_loader.next()\n",
    "        # 9's represent tumors\n",
    "        all_tumor_cell_images = batch[mnist_labels == 9]\n",
    "        # everything else except 6's healthy cells\n",
    "        all_healthy_cell_images = batch[(mnist_labels != 9) & (mnist_labels != 6)]\n",
    "        \n",
    "        for _ in range(partitions_count):\n",
    "            items_per_class_count = int(self.total/(num_classes * partitions_count))\n",
    "            \n",
    "            for class_index in range(num_classes):\n",
    "                    uid = self.__generate_for_class(class_index, \n",
    "                                                  items_per_class_count,\n",
    "                                                  class_index,\n",
    "                                                  uid,\n",
    "                                                  all_tumor_cell_images,\n",
    "                                                  all_healthy_cell_images)\n",
    "        self.__store()\n",
    "        print(\"Done.\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, uid):\n",
    "        if torch.is_tensor(uid):\n",
    "            uid = uid.tolist()\n",
    "        label = self.labels[uid]\n",
    "        sample = self.data[uid]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return (sample,label)\n",
    "\n",
    "    def __store(self):\n",
    "        n_partitions = self.n_partitions_train if self.train else self.n_partitions_test\n",
    "        \n",
    "        assert(len(self.data) == len(self.labels))\n",
    "        max_index = len(self.data)\n",
    "        partition_size = max_index/n_partitions\n",
    "        for i in range(n_partitions):\n",
    "            start,end =(int(partition_size * i), int(partition_size * (i+1)))\n",
    "            partition = np.array(self.data[start:end])\n",
    "            np.save(os.path.join(self.dir, \"part_\" + str(i)), partition)\n",
    "        \n",
    "        np.save(os.path.join(self.dir, \"labels\"), np.array(self.labels))\n",
    "        \n",
    "        if not self.train:\n",
    "            np.save(os.path.join(self.dir, \"sources\"), np.array(self.source_images))\n",
    "        \n",
    "    \n",
    "    def __load_data(self):\n",
    "        n_partitions = self.n_partitions_train if self.train else self.n_partitions_test\n",
    "        data = []\n",
    "        for i in range(n_partitions):\n",
    "            data.append(np.load(os.path.join(self.dir, \"part_\" + str(i)+\".npy\")))\n",
    "        self.data = np.vstack(data)\n",
    "        self.labels = np.load(os.path.join(self.dir, \"labels.npy\"))\n",
    "        if not self.train:\n",
    "            self.source_images = np.load(os.path.join(self.dir, \"sources.npy\"),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetType(Enum):\n",
    "    TRAIN = 1\n",
    "    VALID = 2\n",
    "    TEST  = 3\n",
    "    \n",
    "class DatasetLocator():\n",
    "    def __init__(self, conf: Config):\n",
    "        \n",
    "        self.dataset = conf.dataset\n",
    "        self.gpu_run = conf.use_gpu\n",
    "        self.batch_size = conf.batch_size\n",
    "        train, valid, test = self.__load_data()\n",
    "        \n",
    "        self.dataset_dict = {\n",
    "            DatasetType.TRAIN: train,\n",
    "            DatasetType.VALID: valid,\n",
    "            DatasetType.TEST: test\n",
    "        }\n",
    "        \n",
    "    def __f(self,imapge):\n",
    "        np_image = np.array(image)\n",
    "        input_dim = np_image.shape[-1]\n",
    "        new_image = np.zeros(shape=(60,60), dtype = np.float32)\n",
    "        i, j = np.random.randint(0, 60  - input_dim, size = 2)\n",
    "        new_image[i:i+input_dim, j:j+input_dim] = np_image\n",
    "        return new_image\n",
    "    \n",
    "    def __transformed_mnist_transformation(self):\n",
    "        return transforms.Compose(\n",
    "            [torchvision.transforms.Lambda(self.__f),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    def __augmented_mnist_transformation(self):\n",
    "        return transforms.Compose([\n",
    "            torchvision.transforms.RandomAffine(degrees = (-180,180),scale = (0.5,1.0),),\n",
    "            torchvision.transforms.ToTensor()])\n",
    "    \n",
    "    def __augmented_mnist_simple_transformation(self):\n",
    "        return transforms.Compose([\n",
    "            torchvision.transforms.RandomAffine(degrees = (0,90),scale = (0.9,1.0),),\n",
    "            torchvision.transforms.ToTensor()])\n",
    "\n",
    "    def __load_data(self):\n",
    "        train_total = self.__load_dataset(True)\n",
    "        test = self.__load_dataset(False)\n",
    "        \n",
    "        train_length = int(len(train_total) * 0.9)\n",
    "        valid_length = len(train_total) - train_length\n",
    "        (train, valid) = torch.utils.data.random_split(train_total,(train_length, valid_length))\n",
    "        return (train, valid, test)\n",
    "    \n",
    "    def __load_dataset(self, is_train):\n",
    "        if self.dataset == DatasetName.MNIST:\n",
    "            transform = torchvision.transforms.ToTensor()\n",
    "        elif self.dataset == DatasetName.AUGMENTED:\n",
    "            transform = self.__augmented_mnist_transformation()\n",
    "        elif self.dataset == DatasetName.TRANSFORMED:\n",
    "            transform = self.__transformed_mnist_transformation()\n",
    "        elif self.dataset == DatasetName.AUGMENTED_MEDICAL:\n",
    "            return AugmentedMedicalMNISTDataset(root_dir='.', data_dir = \"MEDNIST\",train = is_train, mnist_transform = self.__augmented_mnist_transformation())\n",
    "        elif self.dataset == DatasetName.AUGMENTED_MEDICAL_2:\n",
    "            return AugmentedMedicalMNISTDataset(root_dir='.',data_dir = \"MEDNIST_2\", train = is_train, mnist_transform = transforms.ToTensor())\n",
    "        elif self.dataset == DatasetName.CONSTRUCTED:\n",
    "            return ConstructedDataset(train = is_train)  \n",
    "        return torchvision.datasets.MNIST(root='./data', train = is_train , download = True, transform = transform)\n",
    "        \n",
    "    def data_loader(self, dataset:DatasetType):\n",
    "        should_shuffle = dataset == DatasetType.TRAIN\n",
    "        data = self.dataset_dict[dataset] \n",
    "        return torch.utils.data.DataLoader(data,\n",
    "                                           batch_size = self.batch_size,\n",
    "                                           pin_memory = self.gpu_run,\n",
    "                                           shuffle = should_shuffle,\n",
    "                                           num_workers = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = DatasetLocator(global_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels = iter(locator.data_loader(DatasetType.TRAIN)).next()\n",
    "images = images[0:4]\n",
    "labels = labels[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show(images,labels = None):\n",
    "    if labels == None:\n",
    "        labels = [\" \"] * len(images)\n",
    "    elif isinstance(labels,torch.Tensor): \n",
    "        labels = [label.item() for label in labels]\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(25,25))\n",
    "    for (a,image,label) in zip(axes.ravel(),images,labels):\n",
    "        a.imshow(image[0].numpy(), cmap = plt.cm.gray)\n",
    "        a.set_title(label, fontsize=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "show(images,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def denormalize(T, coords):\n",
    "    return 0.5 * ((coords + 1.0) * T)\n",
    "\n",
    "\n",
    "def bounding_box(x, y, size, color=\"w\"):\n",
    "    x = int(x - (size / 2))\n",
    "    y = int(y - (size / 2))\n",
    "    rect = patches.Rectangle(\n",
    "        (x, y), size, size, linewidth=1, edgecolor=color, fill=False\n",
    "    )\n",
    "    return rect\n",
    "\n",
    "\n",
    "# https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def resize_array(x, size):\n",
    "    # 3D and 4D tensors allowed only\n",
    "    assert x.ndim in [3, 4], \"Only 3D and 4D Tensors allowed!\"\n",
    "\n",
    "    # 4D Tensor\n",
    "    if x.ndim == 4:\n",
    "        res = []\n",
    "        for i in range(x.shape[0]):\n",
    "            img = array2img(x[i])\n",
    "            img = img.resize((size, size))\n",
    "            img = np.asarray(img, dtype=\"float32\")\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            img /= 255.0\n",
    "            res.append(img)\n",
    "        res = np.concatenate(res)\n",
    "        res = np.expand_dims(res, axis=1)\n",
    "        return res\n",
    "\n",
    "    # 3D Tensor\n",
    "    img = array2img(x)\n",
    "    img = img.resize((size, size))\n",
    "    res = np.asarray(img, dtype=\"float32\")\n",
    "    res = np.expand_dims(res, axis=0)\n",
    "    res /= 255.0\n",
    "    return res\n",
    "\n",
    "\n",
    "def img2array(data_path, desired_size=None, expand=False, view=False):\n",
    "    \"\"\"\n",
    "    Util function for loading RGB image into a numpy array.\n",
    "\n",
    "    Returns array of shape (1, H, W, C).\n",
    "    \"\"\"\n",
    "    img = Image.open(data_path)\n",
    "    img = img.convert(\"RGB\")\n",
    "    if desired_size:\n",
    "        img = img.resize((desired_size[1], desired_size[0]))\n",
    "    if view:\n",
    "        img.show()\n",
    "    x = np.asarray(img, dtype=\"float32\")\n",
    "    if expand:\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    x /= 255.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def array2img(x):\n",
    "    \"\"\"\n",
    "    Util function for converting anumpy array to a PIL img.\n",
    "\n",
    "    Returns PIL RGB img.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    x = x + max(-np.min(x), 0)\n",
    "    x_max = np.max(x)\n",
    "    if x_max != 0:\n",
    "        x /= x_max\n",
    "    x *= 255\n",
    "    return Image.fromarray(x.astype(\"uint8\"), \"RGB\")\n",
    "\n",
    "\n",
    "def plot_images(images, gd_truth):\n",
    "\n",
    "    images = images.squeeze()\n",
    "    assert len(images) == len(gd_truth) == 9\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # plot the image\n",
    "        ax.imshow(images[i], cmap=\"Greys_r\")\n",
    "\n",
    "        xlabel = \"{}\".format(gd_truth[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def prepare_dirs(config):\n",
    "    for path in [config.data_dir, config.ckpt_dir, config.logs_dir]:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "\n",
    "def save_config(config):\n",
    "    model_name = \"ram_{}_{}x{}_{}\".format(\n",
    "        config.num_glimpses, config.patch_size, config.patch_size, config.glimpse_scale\n",
    "    )\n",
    "    filename = model_name + \"_params.json\"\n",
    "    param_path = os.path.join(config.ckpt_dir, filename)\n",
    "\n",
    "    print(\"[*] Model Checkpoint Dir: {}\".format(config.ckpt_dir))\n",
    "    print(\"[*] Param Path: {}\".format(param_path))\n",
    "\n",
    "    with open(param_path, \"w\") as fp:\n",
    "        json.dump(config.__dict__, fp, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Normal\n",
    "\n",
    "\n",
    "class Retina:\n",
    "    \"\"\"A visual retina.\n",
    "\n",
    "    Extracts a foveated glimpse `phi` around location `l`\n",
    "    from an image `x`.\n",
    "\n",
    "    Concretely, encodes the region around `l` at a\n",
    "    high-resolution but uses a progressively lower\n",
    "    resolution for pixels further from `l`, resulting\n",
    "    in a compressed representation of the original\n",
    "    image `x`.\n",
    "\n",
    "    Args:\n",
    "        x: a 4D Tensor of shape (B, H, W, C). The minibatch\n",
    "            of images.\n",
    "        l: a 2D Tensor of shape (B, 2). Contains normalized\n",
    "            coordinates in the range [-1, 1].\n",
    "        g: size of the first square patch.\n",
    "        k: number of patches to extract in the glimpse.\n",
    "        s: scaling factor that controls the size of\n",
    "            successive patches.\n",
    "\n",
    "    Returns:\n",
    "        phi: a 5D tensor of shape (B, k, g, g, C). The\n",
    "            foveated glimpse of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, g, k, s):\n",
    "        self.g = g\n",
    "        self.k = k\n",
    "        self.s = s\n",
    "\n",
    "    def foveate(self, x, l):\n",
    "        \"\"\"Extract `k` square patches of size `g`, centered\n",
    "        at location `l`. The initial patch is a square of\n",
    "        size `g`, and each subsequent patch is a square\n",
    "        whose side is `s` times the size of the previous\n",
    "        patch.\n",
    "\n",
    "        The `k` patches are finally resized to (g, g) and\n",
    "        concatenated into a tensor of shape (B, k, g, g, C).\n",
    "        \"\"\"\n",
    "        phi = []\n",
    "        size = self.g\n",
    "\n",
    "        # extract k patches of increasing size\n",
    "        for i in range(self.k):\n",
    "            phi.append(self.extract_patch(x, l, size))\n",
    "            size = int(self.s * size)\n",
    "\n",
    "        # resize the patches to squares of size g\n",
    "        for i in range(1, len(phi)):\n",
    "            k = phi[i].shape[-1] // self.g\n",
    "            phi[i] = F.avg_pool2d(phi[i], k)\n",
    "\n",
    "        # concatenate into a single tensor and flatten\n",
    "        \n",
    "        phi = torch.cat(phi, 1)\n",
    "        #phi = phi.view(phi.shape[0], -1)\n",
    "\n",
    "        return phi\n",
    "\n",
    "    def extract_patch(self, x, l, size):\n",
    "        \"\"\"Extract a single patch for each image in `x`.\n",
    "\n",
    "        Args:\n",
    "        x: a 4D Tensor of shape (B, H, W, C). The minibatch\n",
    "            of images.\n",
    "        l: a 2D Tensor of shape (B, 2).\n",
    "        size: a scalar defining the size of the extracted patch.\n",
    "\n",
    "        Returns:\n",
    "            patch: a 4D Tensor of shape (B, size, size, C)\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        start = self.denormalize(H, l)\n",
    "        end = start + size\n",
    "\n",
    "        # pad with zeros\n",
    "        x = F.pad(x, (size // 2, size // 2, size // 2, size // 2))\n",
    "\n",
    "        # loop through mini-batch and extract patches\n",
    "        patch = []\n",
    "        for i in range(B):\n",
    "            patch.append(x[i, :, start[i, 1] : end[i, 1], start[i, 0] : end[i, 0]])\n",
    "        return torch.stack(patch)\n",
    "\n",
    "    def denormalize(self, T, coords):\n",
    "        \"\"\"Convert coordinates in the range [-1, 1] to\n",
    "        coordinates in the range [0, T] where `T` is\n",
    "        the size of the image.\n",
    "        \"\"\"\n",
    "        return (0.5 * ((coords + 1.0) * T)).long()\n",
    "\n",
    "    def exceeds(self, from_x, to_x, from_y, to_y, T):\n",
    "        \"\"\"Check whether the extracted patch will exceed\n",
    "        the boundaries of the image of size `T`.\n",
    "        \"\"\"\n",
    "        if (from_x < 0) or (from_y < 0) or (to_x > T) or (to_y > T):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class ActionNetwork(nn.Module):\n",
    "    \"\"\"The action network.\n",
    "\n",
    "    Uses the internal state `h_t` of the core network to\n",
    "    produce the final output classification.\n",
    "\n",
    "    Concretely, feeds the hidden state `h_t` through a fc\n",
    "    layer followed by a softmax to create a vector of\n",
    "    output probabilities over the possible classes.\n",
    "\n",
    "    Hence, the environment action `a_t` is drawn from a\n",
    "    distribution conditioned on an affine transformation\n",
    "    of the hidden state vector `h_t`, or in other words,\n",
    "    the action network is simply a linear softmax classifier.\n",
    "\n",
    "    Args:\n",
    "        input_size: input size of the fc layer.\n",
    "        output_size: output size of the fc layer.\n",
    "        h_t: the hidden state vector of the core network\n",
    "            for the current time step `t`.\n",
    "\n",
    "    Returns:\n",
    "        a_t: output probability vector over the classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, h_t):\n",
    "        a_t = F.log_softmax(self.fc(h_t), dim=1)\n",
    "        return a_t\n",
    "\n",
    "\n",
    "class LocationNetwork(nn.Module):\n",
    "    \"\"\"The location network.\n",
    "\n",
    "    Uses the internal state `h_t` of the core network to\n",
    "    produce the location coordinates `l_t` for the next\n",
    "    time step.\n",
    "\n",
    "    Concretely, feeds the hidden state `h_t` through a fc\n",
    "    layer followed by a tanh to clamp the output beween\n",
    "    [-1, 1]. This produces a 2D vector of means used to\n",
    "    parametrize a two-component Gaussian with a fixed\n",
    "    variance from which the location coordinates `l_t`\n",
    "    for the next time step are sampled.\n",
    "\n",
    "    Hence, the location `l_t` is chosen stochastically\n",
    "    from a distribution conditioned on an affine\n",
    "    transformation of the hidden state vector `h_t`.\n",
    "\n",
    "    Args:\n",
    "        input_size: input size of the fc layer.\n",
    "        output_size: output size of the fc layer.\n",
    "        std: standard deviation of the normal distribution.\n",
    "        h_t: the hidden state vector of the core network for\n",
    "            the current time step `t`.\n",
    "\n",
    "    Returns:\n",
    "        mu: a 2D vector of shape (B, 2).\n",
    "        l_t: a 2D vector of shape (B, 2).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, std):\n",
    "        super().__init__()\n",
    "\n",
    "        self.std = std\n",
    "\n",
    "        hid_size = input_size // 2\n",
    "        self.fc = nn.Linear(input_size, hid_size)\n",
    "        self.fc_lt = nn.Linear(hid_size, output_size)\n",
    "\n",
    "    def forward(self, h_t):\n",
    "        # compute mean\n",
    "        feat = F.relu(self.fc(h_t.detach()))\n",
    "        mu = torch.tanh(self.fc_lt(feat))\n",
    "\n",
    "        # reparametrization trick\n",
    "        l_t = torch.distributions.Normal(mu, self.std).rsample()\n",
    "        l_t = l_t.detach()\n",
    "        log_pi = Normal(mu, self.std).log_prob(l_t)\n",
    "\n",
    "        # we assume both dimensions are independent\n",
    "        # 1. pdf of the joint is the product of the pdfs\n",
    "        # 2. log of the product is the sum of the logs\n",
    "        log_pi = torch.sum(log_pi, dim=1)\n",
    "\n",
    "        # bound between [-1, 1]\n",
    "        l_t = torch.clamp(l_t, -1, 1)\n",
    "\n",
    "        return log_pi, l_t\n",
    "\n",
    "\n",
    "class BaselineNetwork(nn.Module):\n",
    "    \"\"\"The baseline network.\n",
    "\n",
    "    This network regresses the baseline in the\n",
    "    reward function to reduce the variance of\n",
    "    the gradient update.\n",
    "\n",
    "    Args:\n",
    "        input_size: input size of the fc layer.\n",
    "        output_size: output size of the fc layer.\n",
    "        h_t: the hidden state vector of the core network\n",
    "            for the current time step `t`.\n",
    "\n",
    "    Returns:\n",
    "        b_t: a 2D vector of shape (B, 1). The baseline\n",
    "            for the current time step `t`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, h_t):\n",
    "        b_t = self.fc(h_t.detach())\n",
    "        return b_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreNetwork(nn.Module):\n",
    "    \"\"\"The core network.\n",
    "    TODO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers  = 2\n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.hidden_state = None\n",
    "        self.cell_state   = None\n",
    "        \n",
    "        # batch_first = true -> (B x SEQ (in this case 1) x Features)\n",
    "        # and SEQ only 1 element\n",
    "        self.stacked_lstm = nn.LSTM(input_size = input_size,\n",
    "                                    hidden_size = hidden_size,\n",
    "                                    num_layers = self.num_layers,\n",
    "                                    batch_first = True)\n",
    "        \n",
    "    def reset(self, batch_size, device):\n",
    "        self.hidden_state = torch.zeros(\n",
    "            (self.num_layers, batch_size, self.hidden_size),\n",
    "            dtype = torch.float,\n",
    "            device = device,\n",
    "            requires_grad = True)\n",
    "        \n",
    "        self.cell_state = torch.zeros(\n",
    "            (self.num_layers, batch_size, self.hidden_size),\n",
    "            dtype = torch.float,\n",
    "            device = device,\n",
    "            requires_grad = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, g_t):\n",
    "        # need to add seq dimension\n",
    "        g_t = g_t.unsqueeze(1)\n",
    "        # output == top layer of h_t. So for 2 layers `o == h_t[1]` yield all true\n",
    "        (output,(self.cell_state, self.hidden_state)) = self.stacked_lstm.forward(g_t,(self.cell_state, self.hidden_state))\n",
    "        # remove seq dimension\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlimpseNetwork(nn.Module):\n",
    "    \"\"\"The glimpse network.\n",
    "\n",
    "    TODO\n",
    "\n",
    "    Args:\n",
    "        h_g: hidden layer size of the fc layer for `phi`.\n",
    "        h_l: hidden layer size of the fc layer for `l`.\n",
    "        g: size of the square patches in the glimpses extracted\n",
    "        by the retina.\n",
    "        k: number of patches to extract per glimpse.\n",
    "        s: scaling factor that controls the size of successive patches.\n",
    "        c: number of channels in each image.\n",
    "        x: a 4D Tensor of shape (B, H, W, C). The minibatch\n",
    "            of images.\n",
    "        l_t_prev: a 2D tensor of shape (B, 2). Contains the glimpse\n",
    "            coordinates [x, y] for the previous timestep `t-1`.\n",
    "\n",
    "    Returns:\n",
    "        g_t: a 2D tensor of shape (B, hidden_size).\n",
    "            The glimpse representation returned by\n",
    "            the glimpse network for the current\n",
    "            timestep `t`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h_g, h_l, g, k, s, c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retina = Retina(g, k, s)\n",
    "        \n",
    "        D_out = h_g + h_l\n",
    "                \n",
    "        # what \n",
    "        \n",
    "        # padding of 1, to ensure same dimensions\n",
    "        self.conv1 = nn.Conv2d(in_channels = k, out_channels = 16, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = self.conv1.out_channels, out_channels = 16, kernel_size = 3, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features = self.conv2.out_channels, track_running_stats = True)\n",
    "         \n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 3, stride = 3, padding = 1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = self.conv2.out_channels, out_channels = 32, kernel_size = 3, padding = 1)\n",
    "\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 3, stride = 3, padding = 1)\n",
    "        \n",
    "        # W * H of previous layer * depth\n",
    "        # W* H altered by max pooling\n",
    "        reduced_dim = math.floor((1 + math.floor((1 + 12 + 1)/3) + 1) / 3)\n",
    "        D_in = self.conv3.out_channels * reduced_dim * reduced_dim\n",
    "        #TODO revert to D_in\n",
    "        self.fc1 = nn.Linear(in_features = 32, out_features = h_g)\n",
    "        self.fc2 = nn.Linear(in_features = h_g, out_features = D_out)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features = D_out, track_running_stats = True)\n",
    "        \n",
    "        # where\n",
    "        # in_features = 2, loc is a tuple of (x,y)\n",
    "        self.loc_fc1 = nn.Linear(in_features = 2, out_features = h_l)\n",
    "        self.loc_fc2 = nn.Linear(in_features = h_l, out_features = D_out)\n",
    "        \n",
    "    def forward(self, x, l_t_prev):\n",
    "        # generate glimpse phi from image x\n",
    "        phi = self.retina.foveate(x, l_t_prev)\n",
    "        # flatten location vector\n",
    "        l_t_prev = l_t_prev.view(l_t_prev.size(0), -1)\n",
    "        # what\n",
    "        # 3 conv layers\n",
    "        h = self.conv1(phi)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.bn1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.max_pool1(h)\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = self.max_pool2(h) \n",
    "      \n",
    "        # flatten\n",
    "        # keep batch dimension and determine other one automatically\n",
    "        h = h.view(x.shape[0],-1)\n",
    "\n",
    "        # fully connected layers\n",
    "        h = self.fc1(h)\n",
    "        h = self.fc2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = F.relu(h)\n",
    "    \n",
    "\n",
    "        # where\n",
    "        l = self.loc_fc1(l_t_prev)\n",
    "        \n",
    "        l = F.relu(l)\n",
    "        l = self.loc_fc2(l)\n",
    "        \n",
    "        # combine what and where\n",
    "        g = F.relu(h * l)\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1800 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_patches():\n",
    "    locs              = torch.zeros((images.shape[0],2))\n",
    "    extracted_patches = Retina(global_config.patch_size,global_config.num_patches,global_config.glimpse_scale).foveate(images,locs)\n",
    "    extracted_patches = extracted_patches.reshape((len(images), global_config.num_patches,global_config.patch_size,global_config.patch_size ))\n",
    "    fig, axes = plt.subplots(len(images), global_config.num_patches + 1, figsize=(25,25))\n",
    "\n",
    "    for patches, image, axis in zip(extracted_patches,images,axes):\n",
    "        for i in range(global_config.num_patches + 1):\n",
    "            im = image[0] if i == 0  else patches[i-1]\n",
    "            scale = global_config.glimpse_scale ** (i-1)\n",
    "            label = \"number: \" + str(labels[i].item()) if i == 0 else \"size: \" +  str(global_config.patch_size) + \" x \" + str(global_config.patch_size) + \" scale: \"+ str(scale)\n",
    "            axis[i].imshow(im.numpy(), cmap = plt.cm.gray)\n",
    "            axis[i].set_title(label, fontsize=20)\n",
    "# extracted at center\n",
    "show_patches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RecurrentAttention(nn.Module):\n",
    "    \"\"\"A Recurrent Model of Visual Attention (RAM) [1].\n",
    "\n",
    "    RAM is a recurrent neural network that processes\n",
    "    inputs sequentially, attending to different locations\n",
    "    within the image one at a time, and incrementally\n",
    "    combining information from these fixations to build\n",
    "    up a dynamic internal representation of the image.\n",
    "\n",
    "    References:\n",
    "      [1]: Minh et. al., https://arxiv.org/abs/1406.6247\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, g, k, s, c, h_g, h_l, std, hidden_size, num_classes,\n",
    "    ):\n",
    "        \"\"\"Constructor.\n",
    "\n",
    "        Args:\n",
    "          g: size of the square patches in the glimpses extracted by the retina.\n",
    "          k: number of patches to extract per glimpse.\n",
    "          s: scaling factor that controls the size of successive patches.\n",
    "          c: number of channels in each image.\n",
    "          h_g: hidden layer size of the fc layer for `phi`.\n",
    "          h_l: hidden layer size of the fc layer for `l`.\n",
    "          std: standard deviation of the Gaussian policy.\n",
    "          hidden_size: hidden size of the rnn.\n",
    "          num_classes: number of classes in the dataset.\n",
    "          num_glimpses: number of glimpses to take per image,\n",
    "            i.e. number of BPTT steps.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.std = std\n",
    "\n",
    "        self.sensor = GlimpseNetwork(h_g, h_l, g, k, s, c)\n",
    "        self.rnn = CoreNetwork(hidden_size, hidden_size)\n",
    "        self.locator = LocationNetwork(hidden_size, 2, std)\n",
    "        self.classifier = ActionNetwork(hidden_size, num_classes)\n",
    "        self.baseliner = BaselineNetwork(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, l_t_prev, last=False):\n",
    "        \"\"\"Run RAM for one timestep on a minibatch of images.\n",
    "\n",
    "        Args:\n",
    "            x: a 4D Tensor of shape (B, H, W, C). The minibatch\n",
    "                of images.\n",
    "            l_t_prev: a 2D tensor of shape (B, 2). The location vector\n",
    "                containing the glimpse coordinates [x, y] for the previous\n",
    "                timestep `t-1`.\n",
    "            h_t_prev: a 2D tensor of shape (B, hidden_size). The hidden\n",
    "                state vector for the previous timestep `t-1`.\n",
    "            last: a bool indicating whether this is the last timestep.\n",
    "                If True, the action network returns an output probability\n",
    "                vector over the classes and the baseline `b_t` for the\n",
    "                current timestep `t`. Else, the core network returns the\n",
    "                hidden state vector for the next timestep `t+1` and the\n",
    "                location vector for the next timestep `t+1`.\n",
    "\n",
    "        Returns:\n",
    "            h_t: a 2D tensor of shape (B, hidden_size). The hidden\n",
    "                state vector for the current timestep `t`.\n",
    "            mu: a 2D tensor of shape (B, 2). The mean that parametrizes\n",
    "                the Gaussian policy.\n",
    "            l_t: a 2D tensor of shape (B, 2). The location vector\n",
    "                containing the glimpse coordinates [x, y] for the\n",
    "                current timestep `t`.\n",
    "            b_t: a vector of length (B,). The baseline for the\n",
    "                current time step `t`.\n",
    "            log_probas: a 2D tensor of shape (B, num_classes). The\n",
    "                output log probability vector over the classes.\n",
    "            log_pi: a vector of length (B,).\n",
    "        \"\"\"\n",
    "        g_t = self.sensor(x, l_t_prev)\n",
    "        h_t = self.rnn(g_t)\n",
    "        log_pi, l_t = self.locator(h_t)\n",
    "        b_t = self.baseliner(h_t).squeeze()\n",
    "\n",
    "        if last:\n",
    "            log_probas = self.classifier(h_t)\n",
    "            return h_t, l_t, b_t, log_probas, log_pi\n",
    "\n",
    "        return h_t, l_t, b_t, log_pi\n",
    "    \n",
    "    def reset(self, batch_size, device):\n",
    "        #h_t maintained by rnn itself\n",
    "        self.rnn.reset(batch_size = batch_size, device = device)\n",
    "\n",
    "        l_t = torch.FloatTensor(batch_size, 2).uniform_(-1, 1).to(device)\n",
    "        l_t.requires_grad = True\n",
    "\n",
    "        return l_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"A Recurrent Attention Model trainer.\n",
    "\n",
    "    All hyperparameters are provided by the user in the\n",
    "    config file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, data_loader):\n",
    "        \"\"\"\n",
    "        Construct a new Trainer instance.\n",
    "\n",
    "        Args:\n",
    "            config: object containing command line arguments.\n",
    "            data_loader: A data iterator.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "        if config.use_gpu and torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "        # glimpse network params\n",
    "        self.patch_size = config.patch_size\n",
    "        self.glimpse_scale = config.glimpse_scale\n",
    "        self.num_patches = config.num_patches\n",
    "        self.loc_hidden = config.loc_hidden\n",
    "        self.glimpse_hidden = config.glimpse_hidden\n",
    "\n",
    "        # core network params\n",
    "        self.num_glimpses = config.num_glimpses\n",
    "        self.hidden_size = config.hidden_size\n",
    "\n",
    "        # reinforce params\n",
    "        self.std = config.std\n",
    "        self.M = config.M\n",
    "\n",
    "        # data params\n",
    "        if config.is_train:\n",
    "            self.train_loader = data_loader[0]\n",
    "            self.valid_loader = data_loader[1]\n",
    "            self.num_train = len(self.train_loader.dataset)\n",
    "            self.num_valid = len(self.valid_loader.dataset)\n",
    "        else:\n",
    "            self.test_loader = data_loader\n",
    "            self.num_test = len(self.test_loader.dataset)\n",
    "        self.num_classes = 10\n",
    "        self.num_channels = 1\n",
    "\n",
    "        # training params\n",
    "        self.epochs = config.epochs\n",
    "        self.start_epoch = 0\n",
    "        self.momentum = config.momentum\n",
    "        self.lr = config.init_lr\n",
    "\n",
    "        # misc params\n",
    "        self.best = config.best\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        self.logs_dir = config.logs_dir\n",
    "        self.best_valid_acc = 0.0\n",
    "        self.counter = 0\n",
    "        self.lr_patience = config.lr_patience\n",
    "        self.train_patience = config.train_patience\n",
    "        self.use_tensorboard = config.use_tensorboard\n",
    "        self.resume = config.resume\n",
    "        self.print_freq = config.print_freq\n",
    "        self.plot_freq = config.plot_freq\n",
    "        self.model_name = config.model_name\n",
    "\n",
    "\n",
    "        self.plot_dir = \"./plots/\" + self.model_name + \"/\"\n",
    "        if not os.path.exists(self.plot_dir):\n",
    "            os.makedirs(self.plot_dir)\n",
    "\n",
    "        # configure tensorboard logging\n",
    "        if self.use_tensorboard:\n",
    "            tensorboard_dir = self.logs_dir + self.model_name\n",
    "            print(\"[*] Saving tensorboard logs to {}\".format(tensorboard_dir))\n",
    "            if not os.path.exists(tensorboard_dir):\n",
    "                os.makedirs(tensorboard_dir)\n",
    "            configure(tensorboard_dir)\n",
    "\n",
    "        # build RAM model\n",
    "        self.model = RecurrentAttention(\n",
    "            self.patch_size,\n",
    "            self.num_patches,\n",
    "            self.glimpse_scale,\n",
    "            self.num_channels,\n",
    "            self.loc_hidden,\n",
    "            self.glimpse_hidden,\n",
    "            self.std,\n",
    "            self.hidden_size,\n",
    "            self.num_classes,\n",
    "        )\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # initialize optimizer and scheduler\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config.init_lr,\n",
    "            weight_decay = self.config.weight_decay\n",
    "        )\n",
    "        self.scheduler = ReduceLROnPlateau(\n",
    "            self.optimizer, \"min\", patience=self.lr_patience\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the model on the training set.\n",
    "\n",
    "        A checkpoint of the model is saved after each epoch\n",
    "        and if the validation accuracy is improved upon,\n",
    "        a separate ckpt is created for use on the test set.\n",
    "        \"\"\"\n",
    "        # load the most recent checkpoint\n",
    "        if self.resume:\n",
    "            self.load_checkpoint(best=False)\n",
    "\n",
    "        print(\n",
    "            \"\\n[*] Train on {} samples, validate on {} samples\".format(\n",
    "                self.num_train, self.num_valid\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for epoch in range(self.start_epoch, self.epochs):\n",
    "\n",
    "            print(\n",
    "                \"\\nEpoch: {}/{} - LR: {:.6f}\".format(\n",
    "                    epoch + 1, self.epochs, self.optimizer.param_groups[0][\"lr\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # train for 1 epoch\n",
    "            train_loss, train_acc = self.train_one_epoch(epoch)\n",
    "\n",
    "            # evaluate on validation set\n",
    "            valid_loss, valid_acc = self.validate(epoch)\n",
    "\n",
    "            # # reduce lr if validation loss plateaus\n",
    "            self.scheduler.step(-valid_acc)\n",
    "\n",
    "            is_best = valid_acc > self.best_valid_acc\n",
    "            msg1 = \"train loss: {:.3f} - train acc: {:.3f} \"\n",
    "            msg2 = \"- val loss: {:.3f} - val acc: {:.3f} - val err: {:.3f}\"\n",
    "            if is_best:\n",
    "                self.counter = 0\n",
    "                msg2 += \" [*]\"\n",
    "            msg = msg1 + msg2\n",
    "            print(\n",
    "                msg.format(\n",
    "                    train_loss, train_acc, valid_loss, valid_acc, 100 - valid_acc\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # check for improvement\n",
    "            if not is_best:\n",
    "                self.counter += 1\n",
    "            if self.counter > self.train_patience:\n",
    "                print(\"[!] No improvement in a while, stopping training.\")\n",
    "                return\n",
    "            self.best_valid_acc = max(valid_acc, self.best_valid_acc)\n",
    "            self.save_checkpoint(\n",
    "                {\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"model_state\": self.model.state_dict(),\n",
    "                    \"optim_state\": self.optimizer.state_dict(),\n",
    "                    \"best_valid_acc\": self.best_valid_acc,\n",
    "                },\n",
    "                is_best,\n",
    "            )\n",
    "\n",
    "    def train_one_epoch(self, epoch):\n",
    "        \"\"\"\n",
    "        Train the model for 1 epoch of the training set.\n",
    "\n",
    "        An epoch corresponds to one full pass through the entire\n",
    "        training set in successive mini-batches.\n",
    "\n",
    "        This is used by train() and should not be called manually.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        batch_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        accs = AverageMeter()\n",
    "\n",
    "        tic = time.time()\n",
    "        with tqdm(total=self.num_train) as pbar:\n",
    "            for i, (x, y) in enumerate(self.train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "                plot = False\n",
    "                if (epoch % self.plot_freq == 0) and (i == 0):\n",
    "                    plot = True\n",
    "\n",
    "                # initialize location vector and hidden state\n",
    "                self.batch_size = x.shape[0]\n",
    "                l_t = self.model.reset(self.batch_size, self.device)\n",
    "\n",
    "                # save images\n",
    "                imgs = []\n",
    "                imgs.append(x[0:9])\n",
    "\n",
    "                # extract the glimpses\n",
    "                locs = []\n",
    "                log_pi = []\n",
    "                baselines = []\n",
    "                for t in range(self.num_glimpses - 1):\n",
    "                    # forward pass through model\n",
    "                    h_t, l_t, b_t, p = self.model(x, l_t)\n",
    "\n",
    "                    # store\n",
    "                    locs.append(l_t[0:9])\n",
    "                    baselines.append(b_t)\n",
    "                    log_pi.append(p)\n",
    "\n",
    "                # last iteration\n",
    "                h_t, l_t, b_t, log_probas, p = self.model(x, l_t, last=True)\n",
    "                log_pi.append(p)\n",
    "                baselines.append(b_t)\n",
    "                locs.append(l_t[0:9])\n",
    "\n",
    "                # convert list to tensors and reshape\n",
    "                baselines = torch.stack(baselines).transpose(1, 0)\n",
    "                log_pi = torch.stack(log_pi).transpose(1, 0)\n",
    "\n",
    "                # calculate reward\n",
    "                predicted = torch.max(log_probas, 1)[1]\n",
    "                R = (predicted.detach() == y).float()\n",
    "                R = R.unsqueeze(1).repeat(1, self.num_glimpses)\n",
    "\n",
    "                # compute losses for differentiable modules\n",
    "                loss_action = F.nll_loss(log_probas, y)\n",
    "                loss_baseline = F.mse_loss(baselines, R)\n",
    "\n",
    "                # compute reinforce loss\n",
    "                # summed over timesteps and averaged across batch\n",
    "                adjusted_reward = R - baselines.detach()\n",
    "                loss_reinforce = torch.sum(-log_pi * adjusted_reward, dim=1)\n",
    "                loss_reinforce = torch.mean(loss_reinforce, dim=0)\n",
    "\n",
    "                # sum up into a hybrid loss\n",
    "                loss = loss_action + loss_baseline + loss_reinforce * 0.01\n",
    "\n",
    "                # compute accuracy\n",
    "                correct = (predicted == y).float()\n",
    "                acc = 100 * (correct.sum() / len(y))\n",
    "\n",
    "                # store\n",
    "                losses.update(loss.item(), x.size()[0])\n",
    "                accs.update(acc.item(), x.size()[0])\n",
    "\n",
    "                # compute gradients and update SGD\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # measure elapsed time\n",
    "                toc = time.time()\n",
    "                batch_time.update(toc - tic)\n",
    "\n",
    "                pbar.set_description(\n",
    "                    (\n",
    "                        \"{:.1f}s - loss: {:.3f} - acc: {:.3f}\".format(\n",
    "                            (toc - tic), loss.item(), acc.item()\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(self.batch_size)\n",
    "\n",
    "                # dump the glimpses and locs\n",
    "                if plot:\n",
    "                    imgs = [g.cpu().data.numpy().squeeze() for g in imgs]\n",
    "                    locs = [l.cpu().data.numpy() for l in locs]\n",
    "                    pickle.dump(\n",
    "                        imgs, open(self.plot_dir + \"g_{}.p\".format(epoch + 1), \"wb\")\n",
    "                    )\n",
    "                    pickle.dump(\n",
    "                        locs, open(self.plot_dir + \"l_{}.p\".format(epoch + 1), \"wb\")\n",
    "                    )\n",
    "\n",
    "                # log to tensorboard\n",
    "                if self.use_tensorboard:\n",
    "                    iteration = epoch * len(self.train_loader) + i\n",
    "                    log_value(\"train_loss\", losses.avg, iteration)\n",
    "                    log_value(\"train_acc\", accs.avg, iteration)\n",
    "\n",
    "            return losses.avg, accs.avg\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, epoch):\n",
    "        \"\"\"Evaluate the RAM model on the validation set.\n",
    "        \"\"\"\n",
    "        losses = AverageMeter()\n",
    "        accs = AverageMeter()\n",
    "\n",
    "        for i, (x, y) in enumerate(self.valid_loader):\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "            # duplicate M times\n",
    "            x = x.repeat(self.M, 1, 1, 1)\n",
    "\n",
    "            # initialize location vector and hidden state\n",
    "            self.batch_size = x.shape[0]\n",
    "            l_t = self.model.reset(self.batch_size, self.device)\n",
    "\n",
    "            # extract the glimpses\n",
    "            log_pi = []\n",
    "            baselines = []\n",
    "            for t in range(self.num_glimpses - 1):\n",
    "                # forward pass through model\n",
    "                h_t, l_t, b_t, p = self.model(x, l_t)\n",
    "\n",
    "                # store\n",
    "                baselines.append(b_t)\n",
    "                log_pi.append(p)\n",
    "\n",
    "            # last iteration\n",
    "            h_t, l_t, b_t, log_probas, p = self.model(x, l_t, last=True)\n",
    "            log_pi.append(p)\n",
    "            baselines.append(b_t)\n",
    "\n",
    "            # convert list to tensors and reshape\n",
    "            baselines = torch.stack(baselines).transpose(1, 0)\n",
    "            log_pi = torch.stack(log_pi).transpose(1, 0)\n",
    "\n",
    "            # average\n",
    "            log_probas = log_probas.view(self.M, -1, log_probas.shape[-1])\n",
    "            log_probas = torch.mean(log_probas, dim=0)\n",
    "\n",
    "            baselines = baselines.contiguous().view(self.M, -1, baselines.shape[-1])\n",
    "            baselines = torch.mean(baselines, dim=0)\n",
    "\n",
    "            log_pi = log_pi.contiguous().view(self.M, -1, log_pi.shape[-1])\n",
    "            log_pi = torch.mean(log_pi, dim=0)\n",
    "\n",
    "            # calculate reward\n",
    "            predicted = torch.max(log_probas, 1)[1]\n",
    "            R = (predicted.detach() == y).float()\n",
    "            R = R.unsqueeze(1).repeat(1, self.num_glimpses)\n",
    "\n",
    "            # compute losses for differentiable modules\n",
    "            loss_action = F.nll_loss(log_probas, y)\n",
    "            loss_baseline = F.mse_loss(baselines, R)\n",
    "\n",
    "            # compute reinforce loss\n",
    "            adjusted_reward = R - baselines.detach()\n",
    "            loss_reinforce = torch.sum(-log_pi * adjusted_reward, dim=1)\n",
    "            loss_reinforce = torch.mean(loss_reinforce, dim=0)\n",
    "\n",
    "            # sum up into a hybrid loss\n",
    "            loss = loss_action + loss_baseline + loss_reinforce * 0.01\n",
    "\n",
    "            # compute accuracy\n",
    "            correct = (predicted == y).float()\n",
    "            acc = 100 * (correct.sum() / len(y))\n",
    "\n",
    "            # store\n",
    "            losses.update(loss.item(), x.size()[0])\n",
    "            accs.update(acc.item(), x.size()[0])\n",
    "\n",
    "            # log to tensorboard\n",
    "            if self.use_tensorboard:\n",
    "                iteration = epoch * len(self.valid_loader) + i\n",
    "                log_value(\"valid_loss\", losses.avg, iteration)\n",
    "                log_value(\"valid_acc\", accs.avg, iteration)\n",
    "\n",
    "        return losses.avg, accs.avg\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self):\n",
    "        \"\"\"Test the RAM model.\n",
    "\n",
    "        This function should only be called at the very\n",
    "        end once the model has finished training.\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        preds = []\n",
    "        # load the best checkpoint\n",
    "        self.load_checkpoint(best=self.best)\n",
    "\n",
    "        for i, (x, y) in enumerate(self.test_loader):\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "\n",
    "            # duplicate M times\n",
    "            x = x.repeat(self.M, 1, 1, 1)\n",
    "\n",
    "            # initialize location vector and hidden state\n",
    "            self.batch_size = x.shape[0]\n",
    "            l_t = self.model.reset(self.batch_size, self.device)\n",
    "\n",
    "            # extract the glimpses\n",
    "            for t in range(self.num_glimpses - 1):\n",
    "                # forward pass through model\n",
    "                h_t, l_t, b_t, p = self.model(x, l_t)\n",
    "\n",
    "            # last iteration\n",
    "            h_t, l_t, b_t, log_probas, p = self.model(x, l_t, last=True)\n",
    "\n",
    "            log_probas = log_probas.view(self.M, -1, log_probas.shape[-1])\n",
    "            log_probas = torch.mean(log_probas, dim=0)\n",
    "\n",
    "            pred = log_probas.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "            preds.append(pred)\n",
    "        perc = (100.0 * correct) / (self.num_test)\n",
    "        error = 100 - perc\n",
    "        print(\n",
    "            \"[*] Test Acc: {}/{} ({:.2f}% - {:.2f}%)\".format(\n",
    "                correct, self.num_test, perc, error\n",
    "            )\n",
    "        )\n",
    "        return preds\n",
    "\n",
    "    def save_checkpoint(self, state, is_best):\n",
    "        \"\"\"Saves a checkpoint of the model.\n",
    "\n",
    "        If this model has reached the best validation accuracy thus\n",
    "        far, a seperate file with the suffix `best` is created.\n",
    "        \"\"\"\n",
    "        filename = self.model_name + \"_ckpt.pth.tar\"\n",
    "        ckpt_path = os.path.join(self.ckpt_dir, filename)\n",
    "        torch.save(state, ckpt_path)\n",
    "        if is_best:\n",
    "            filename = self.model_name + \"_model_best.pth.tar\"\n",
    "            shutil.copyfile(ckpt_path, os.path.join(self.ckpt_dir, filename))\n",
    "\n",
    "    def load_checkpoint(self, best=False):\n",
    "        \"\"\"Load the best copy of a model.\n",
    "\n",
    "        This is useful for 2 cases:\n",
    "        - Resuming training with the most recent model checkpoint.\n",
    "        - Loading the best validation model to evaluate on the test data.\n",
    "\n",
    "        Args:\n",
    "            best: if set to True, loads the best model.\n",
    "                Use this if you want to evaluate your model\n",
    "                on the test data. Else, set to False in which\n",
    "                case the most recent version of the checkpoint\n",
    "                is used.\n",
    "        \"\"\"\n",
    "        print(\"[*] Loading model from {}\".format(self.ckpt_dir))\n",
    "\n",
    "        filename = self.model_name + \"_ckpt.pth.tar\"\n",
    "        if best:\n",
    "            filename = self.model_name + \"_model_best.pth.tar\"\n",
    "        ckpt_path = os.path.join(self.ckpt_dir, filename)\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "        # load variables from checkpoint\n",
    "        self.start_epoch = ckpt[\"epoch\"]\n",
    "        self.best_valid_acc = ckpt[\"best_valid_acc\"]\n",
    "        self.model.load_state_dict(ckpt[\"model_state\"])\n",
    "        self.optimizer.load_state_dict(ckpt[\"optim_state\"])\n",
    "\n",
    "        if best:\n",
    "            print(\n",
    "                \"[*] Loaded {} checkpoint @ epoch {} \"\n",
    "                \"with best valid acc of {:.3f}\".format(\n",
    "                    filename, ckpt[\"epoch\"], ckpt[\"best_valid_acc\"]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\"[*] Loaded {} checkpoint @ epoch {}\".format(filename, ckpt[\"epoch\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def main(config):\n",
    "    prepare_dirs(config)\n",
    "\n",
    "    kwargs = {}\n",
    "    if config.use_gpu:\n",
    "        torch.cuda.manual_seed(config.random_seed)\n",
    "        kwargs = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "\n",
    "    # instantiate data loaders\n",
    "    if config.is_train:\n",
    "        train_loader = locator.data_loader(DatasetType.TRAIN)\n",
    "        valid_loader = locator.data_loader(DatasetType.VALID)\n",
    "        dloader = (train_loader,valid_loader)\n",
    "    else:\n",
    "        dloader = locator.data_loader(DatasetType.TEST)\n",
    "\n",
    "    trainer = Trainer(config, dloader)\n",
    "\n",
    "    # either train\n",
    "    if config.is_train:\n",
    "        trainer.train()\n",
    "    # or load a pretrained model and test\n",
    "    else:\n",
    "        trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*] Train on 3600 samples, validate on 400 samples\n",
      "\n",
      "Epoch: 1/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19.5s - loss: 1.731 - acc: 25.000: 100%|██████████| 3600/3600 [00:19<00:00, 185.16it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.089 - train acc: 25.056 - val loss: 1.678 - val acc: 26.750 - val err: 73.250 [*]\n",
      "\n",
      "Epoch: 2/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.0s - loss: 1.595 - acc: 25.000: 100%|██████████| 3600/3600 [00:16<00:00, 224.83it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.589 - train acc: 24.472 - val loss: 1.589 - val acc: 26.750 - val err: 73.250\n",
      "\n",
      "Epoch: 3/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.9s - loss: 1.583 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 227.07it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.576 - train acc: 24.611 - val loss: 1.570 - val acc: 22.500 - val err: 77.500\n",
      "\n",
      "Epoch: 4/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.590 - acc: 18.750: 100%|██████████| 3600/3600 [00:15<00:00, 230.40it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.576 - train acc: 24.250 - val loss: 1.576 - val acc: 27.000 - val err: 73.000 [*]\n",
      "\n",
      "Epoch: 5/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28.1s - loss: 1.568 - acc: 12.500: 100%|██████████| 3600/3600 [00:28<00:00, 128.08it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.575 - train acc: 25.056 - val loss: 1.563 - val acc: 22.500 - val err: 77.500\n",
      "\n",
      "Epoch: 6/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.567 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 235.16it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.571 - train acc: 24.806 - val loss: 1.597 - val acc: 30.000 - val err: 70.000 [*]\n",
      "\n",
      "Epoch: 7/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.4s - loss: 1.571 - acc: 25.000: 100%|██████████| 3600/3600 [00:14<00:00, 249.65it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.585 - train acc: 28.139 - val loss: 1.563 - val acc: 28.000 - val err: 72.000\n",
      "\n",
      "Epoch: 8/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.0s - loss: 1.599 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 256.31it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.572 - train acc: 32.139 - val loss: 1.553 - val acc: 33.750 - val err: 66.250 [*]\n",
      "\n",
      "Epoch: 9/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.4s - loss: 1.646 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 250.36it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.564 - train acc: 33.333 - val loss: 1.543 - val acc: 32.250 - val err: 67.750\n",
      "\n",
      "Epoch: 10/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.0s - loss: 1.479 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 256.60it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.542 - train acc: 35.889 - val loss: 1.536 - val acc: 37.750 - val err: 62.250 [*]\n",
      "\n",
      "Epoch: 11/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.2s - loss: 1.462 - acc: 18.750: 100%|██████████| 3600/3600 [00:14<00:00, 253.59it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.535 - train acc: 36.139 - val loss: 1.508 - val acc: 35.750 - val err: 64.250\n",
      "\n",
      "Epoch: 12/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.2s - loss: 1.381 - acc: 68.750: 100%|██████████| 3600/3600 [00:14<00:00, 254.26it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.542 - train acc: 37.167 - val loss: 1.549 - val acc: 32.500 - val err: 67.500\n",
      "\n",
      "Epoch: 13/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.1s - loss: 1.632 - acc: 25.000: 100%|██████████| 3600/3600 [00:14<00:00, 254.77it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.522 - train acc: 37.417 - val loss: 1.486 - val acc: 35.500 - val err: 64.500\n",
      "\n",
      "Epoch: 14/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.3s - loss: 1.455 - acc: 25.000: 100%|██████████| 3600/3600 [00:14<00:00, 250.76it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.500 - train acc: 39.167 - val loss: 1.516 - val acc: 35.750 - val err: 64.250\n",
      "\n",
      "Epoch: 15/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.373 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 247.00it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.495 - train acc: 39.583 - val loss: 1.521 - val acc: 36.000 - val err: 64.000\n",
      "\n",
      "Epoch: 16/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.4s - loss: 1.603 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 249.89it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.492 - train acc: 40.028 - val loss: 1.495 - val acc: 39.000 - val err: 61.000 [*]\n",
      "\n",
      "Epoch: 17/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.8s - loss: 1.489 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 243.21it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.479 - train acc: 39.778 - val loss: 1.521 - val acc: 30.250 - val err: 69.750\n",
      "\n",
      "Epoch: 18/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.527 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 246.83it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.481 - train acc: 39.583 - val loss: 1.504 - val acc: 38.750 - val err: 61.250\n",
      "\n",
      "Epoch: 19/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.633 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 246.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.482 - train acc: 41.306 - val loss: 1.534 - val acc: 33.750 - val err: 66.250\n",
      "\n",
      "Epoch: 20/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.7s - loss: 1.536 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 245.54it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.480 - train acc: 40.444 - val loss: 1.516 - val acc: 40.500 - val err: 59.500 [*]\n",
      "\n",
      "Epoch: 21/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.8s - loss: 1.354 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 243.68it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.465 - train acc: 41.111 - val loss: 1.471 - val acc: 38.750 - val err: 61.250\n",
      "\n",
      "Epoch: 22/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.2s - loss: 1.523 - acc: 25.000: 100%|██████████| 3600/3600 [00:14<00:00, 254.13it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.456 - train acc: 41.111 - val loss: 1.463 - val acc: 39.000 - val err: 61.000\n",
      "\n",
      "Epoch: 23/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.4s - loss: 1.243 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 250.14it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.437 - train acc: 42.250 - val loss: 1.448 - val acc: 42.500 - val err: 57.500 [*]\n",
      "\n",
      "Epoch: 24/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.5s - loss: 1.527 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 248.60it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.427 - train acc: 43.694 - val loss: 1.461 - val acc: 38.000 - val err: 62.000\n",
      "\n",
      "Epoch: 25/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.416 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 246.31it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.438 - train acc: 42.861 - val loss: 1.422 - val acc: 41.500 - val err: 58.500\n",
      "\n",
      "Epoch: 26/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.5s - loss: 1.536 - acc: 25.000: 100%|██████████| 3600/3600 [00:14<00:00, 248.79it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.439 - train acc: 43.139 - val loss: 1.489 - val acc: 37.500 - val err: 62.500\n",
      "\n",
      "Epoch: 27/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.357 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 246.66it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.438 - train acc: 42.917 - val loss: 1.469 - val acc: 41.000 - val err: 59.000\n",
      "\n",
      "Epoch: 28/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.5s - loss: 1.592 - acc: 12.500: 100%|██████████| 3600/3600 [00:14<00:00, 248.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.433 - train acc: 42.667 - val loss: 1.459 - val acc: 42.000 - val err: 58.000\n",
      "\n",
      "Epoch: 29/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.5s - loss: 1.541 - acc: 25.000: 100%|██████████| 3600/3600 [00:14<00:00, 248.60it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.422 - train acc: 42.472 - val loss: 1.441 - val acc: 40.500 - val err: 59.500\n",
      "\n",
      "Epoch: 30/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.4s - loss: 1.690 - acc: 12.500: 100%|██████████| 3600/3600 [00:14<00:00, 250.22it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.431 - train acc: 42.861 - val loss: 1.462 - val acc: 43.750 - val err: 56.250 [*]\n",
      "\n",
      "Epoch: 31/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.395 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 247.12it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.436 - train acc: 41.694 - val loss: 1.445 - val acc: 39.750 - val err: 60.250\n",
      "\n",
      "Epoch: 32/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.1s - loss: 1.853 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 256.03it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.438 - train acc: 42.250 - val loss: 1.429 - val acc: 41.250 - val err: 58.750\n",
      "\n",
      "Epoch: 33/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.7s - loss: 1.537 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 244.72it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.421 - train acc: 42.611 - val loss: 1.426 - val acc: 40.500 - val err: 59.500\n",
      "\n",
      "Epoch: 34/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.7s - loss: 1.581 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 245.43it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.420 - train acc: 44.972 - val loss: 1.447 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 35/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.7s - loss: 1.676 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 244.89it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.410 - train acc: 43.778 - val loss: 1.436 - val acc: 45.250 - val err: 54.750 [*]\n",
      "\n",
      "Epoch: 36/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.7s - loss: 1.466 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 244.15it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.408 - train acc: 44.083 - val loss: 1.443 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 37/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.295 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.93it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.391 - train acc: 45.806 - val loss: 1.423 - val acc: 43.000 - val err: 57.000\n",
      "\n",
      "Epoch: 38/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.7s - loss: 1.340 - acc: 56.250: 100%|██████████| 3600/3600 [00:14<00:00, 245.63it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.418 - train acc: 45.222 - val loss: 1.446 - val acc: 41.750 - val err: 58.250\n",
      "\n",
      "Epoch: 39/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.623 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 245.85it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.421 - train acc: 43.889 - val loss: 1.498 - val acc: 38.500 - val err: 61.500\n",
      "\n",
      "Epoch: 40/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.533 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 240.90it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.417 - train acc: 43.667 - val loss: 1.426 - val acc: 42.000 - val err: 58.000\n",
      "\n",
      "Epoch: 41/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.8s - loss: 1.524 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 242.55it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.432 - train acc: 43.139 - val loss: 1.472 - val acc: 39.250 - val err: 60.750\n",
      "\n",
      "Epoch: 42/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.474 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 247.23it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.487 - train acc: 40.389 - val loss: 1.464 - val acc: 40.000 - val err: 60.000\n",
      "\n",
      "Epoch: 43/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.5s - loss: 1.337 - acc: 56.250: 100%|██████████| 3600/3600 [00:14<00:00, 247.70it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.468 - train acc: 41.139 - val loss: 1.475 - val acc: 40.000 - val err: 60.000\n",
      "\n",
      "Epoch: 44/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.8s - loss: 1.230 - acc: 56.250: 100%|██████████| 3600/3600 [00:14<00:00, 243.62it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.483 - train acc: 40.694 - val loss: 1.453 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 45/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.606 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 246.97it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.462 - train acc: 41.000 - val loss: 1.461 - val acc: 39.250 - val err: 60.750\n",
      "\n",
      "Epoch: 46/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.8s - loss: 1.424 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 242.48it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.451 - train acc: 42.861 - val loss: 1.475 - val acc: 40.000 - val err: 60.000\n",
      "\n",
      "Epoch: 47/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.677 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 247.26it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.459 - train acc: 41.944 - val loss: 1.504 - val acc: 34.500 - val err: 65.500\n",
      "\n",
      "Epoch: 48/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.462 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.06it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.456 - train acc: 41.583 - val loss: 1.465 - val acc: 40.750 - val err: 59.250\n",
      "\n",
      "Epoch: 49/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.4s - loss: 1.712 - acc: 18.750: 100%|██████████| 3600/3600 [00:14<00:00, 249.48it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.443 - train acc: 42.806 - val loss: 1.478 - val acc: 40.500 - val err: 59.500\n",
      "\n",
      "Epoch: 50/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.7s - loss: 1.426 - acc: 56.250: 100%|██████████| 3600/3600 [00:14<00:00, 244.63it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.426 - train acc: 42.361 - val loss: 1.491 - val acc: 35.250 - val err: 64.750\n",
      "\n",
      "Epoch: 51/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.8s - loss: 1.551 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 242.80it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.427 - train acc: 44.139 - val loss: 1.448 - val acc: 40.500 - val err: 59.500\n",
      "\n",
      "Epoch: 52/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.501 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 240.49it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.418 - train acc: 44.167 - val loss: 1.459 - val acc: 41.750 - val err: 58.250\n",
      "\n",
      "Epoch: 53/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.635 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 240.90it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.425 - train acc: 43.972 - val loss: 1.450 - val acc: 42.000 - val err: 58.000\n",
      "\n",
      "Epoch: 54/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.462 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.75it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.402 - train acc: 43.250 - val loss: 1.452 - val acc: 37.750 - val err: 62.250\n",
      "\n",
      "Epoch: 55/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.257 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 233.38it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.410 - train acc: 44.028 - val loss: 1.442 - val acc: 40.500 - val err: 59.500\n",
      "\n",
      "Epoch: 56/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.520 - acc: 18.750: 100%|██████████| 3600/3600 [00:15<00:00, 232.97it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.410 - train acc: 45.333 - val loss: 1.429 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 57/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.453 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.08it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.384 - train acc: 44.833 - val loss: 1.401 - val acc: 43.000 - val err: 57.000\n",
      "\n",
      "Epoch: 58/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.315 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.38it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.397 - train acc: 45.417 - val loss: 1.411 - val acc: 41.500 - val err: 58.500\n",
      "\n",
      "Epoch: 59/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.772 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 234.89it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.384 - train acc: 45.028 - val loss: 1.441 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 60/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.231 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.43it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.377 - train acc: 45.944 - val loss: 1.448 - val acc: 41.500 - val err: 58.500\n",
      "\n",
      "Epoch: 61/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.366 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.51it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.369 - train acc: 46.361 - val loss: 1.455 - val acc: 40.250 - val err: 59.750\n",
      "\n",
      "Epoch: 62/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.429 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.57it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.383 - train acc: 45.778 - val loss: 1.395 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 63/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.7s - loss: 1.182 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 229.92it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.381 - train acc: 45.417 - val loss: 1.455 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 64/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.596 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 242.05it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.372 - train acc: 45.583 - val loss: 1.442 - val acc: 41.000 - val err: 59.000\n",
      "\n",
      "Epoch: 65/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.464 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 230.36it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.365 - train acc: 46.111 - val loss: 1.408 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 66/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27.9s - loss: 1.395 - acc: 37.500: 100%|██████████| 3600/3600 [00:27<00:00, 129.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.370 - train acc: 47.083 - val loss: 1.408 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 67/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.597 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 233.72it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.353 - train acc: 47.083 - val loss: 1.375 - val acc: 45.750 - val err: 54.250 [*]\n",
      "\n",
      "Epoch: 68/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.332 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 238.30it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.363 - train acc: 47.083 - val loss: 1.394 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 69/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.494 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 242.10it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.353 - train acc: 47.222 - val loss: 1.437 - val acc: 43.000 - val err: 57.000\n",
      "\n",
      "Epoch: 70/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.627 - acc: 18.750: 100%|██████████| 3600/3600 [00:15<00:00, 235.81it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.372 - train acc: 46.417 - val loss: 1.362 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 71/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.682 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.98it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.353 - train acc: 47.417 - val loss: 1.411 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 72/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.802 - acc: 12.500: 100%|██████████| 3600/3600 [00:14<00:00, 241.09it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.356 - train acc: 47.944 - val loss: 1.416 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 73/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.485 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.68it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.361 - train acc: 46.556 - val loss: 1.432 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 74/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.493 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.76it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.362 - train acc: 46.278 - val loss: 1.396 - val acc: 47.000 - val err: 53.000 [*]\n",
      "\n",
      "Epoch: 75/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.786 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 235.31it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.349 - train acc: 46.417 - val loss: 1.434 - val acc: 42.000 - val err: 58.000\n",
      "\n",
      "Epoch: 76/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.316 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.20it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.861 - val loss: 1.420 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 77/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.122 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 232.05it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.354 - train acc: 46.444 - val loss: 1.363 - val acc: 48.750 - val err: 51.250 [*]\n",
      "\n",
      "Epoch: 78/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.8s - loss: 1.532 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 243.47it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.353 - train acc: 47.417 - val loss: 1.389 - val acc: 44.000 - val err: 56.000\n",
      "\n",
      "Epoch: 79/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.482 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.58it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.360 - train acc: 46.167 - val loss: 1.397 - val acc: 41.750 - val err: 58.250\n",
      "\n",
      "Epoch: 80/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.451 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.19it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.338 - train acc: 47.750 - val loss: 1.429 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 81/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.5s - loss: 1.450 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 247.58it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.346 - train acc: 48.139 - val loss: 1.445 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 82/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.302 - acc: 56.250: 100%|██████████| 3600/3600 [00:14<00:00, 240.18it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.340 - train acc: 48.083 - val loss: 1.437 - val acc: 40.750 - val err: 59.250\n",
      "\n",
      "Epoch: 83/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.506 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 240.13it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.347 - train acc: 47.944 - val loss: 1.444 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 84/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.308 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 240.86it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.354 - train acc: 47.278 - val loss: 1.464 - val acc: 42.500 - val err: 57.500\n",
      "\n",
      "Epoch: 85/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.400 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 234.02it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.338 - train acc: 48.806 - val loss: 1.423 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 86/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.419 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.30it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.354 - train acc: 47.722 - val loss: 1.400 - val acc: 44.000 - val err: 56.000\n",
      "\n",
      "Epoch: 87/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.552 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 240.07it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.334 - train acc: 48.583 - val loss: 1.373 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 88/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.513 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 240.32it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 47.528 - val loss: 1.352 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 89/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.484 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 240.69it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.340 - train acc: 48.861 - val loss: 1.387 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 90/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.384 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.57it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.346 - train acc: 47.722 - val loss: 1.383 - val acc: 47.750 - val err: 52.250\n",
      "\n",
      "Epoch: 91/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.401 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.66it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.335 - train acc: 47.278 - val loss: 1.391 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 92/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.413 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 232.91it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.336 - train acc: 48.889 - val loss: 1.394 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 93/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.243 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.14it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.342 - train acc: 47.667 - val loss: 1.381 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 94/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.484 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 239.50it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.343 - train acc: 46.889 - val loss: 1.386 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 95/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.097 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.06it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.334 - train acc: 48.056 - val loss: 1.412 - val acc: 46.250 - val err: 53.750\n",
      "\n",
      "Epoch: 96/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 0.918 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 235.62it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 47.972 - val loss: 1.415 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 97/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.2s - loss: 1.320 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 252.82it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.336 - train acc: 47.806 - val loss: 1.364 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 98/500 - LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.499 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 240.09it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.325 - train acc: 48.972 - val loss: 1.399 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 99/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.823 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.79it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.346 - train acc: 47.639 - val loss: 1.379 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 100/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.435 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.78it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 47.917 - val loss: 1.419 - val acc: 41.500 - val err: 58.500\n",
      "\n",
      "Epoch: 101/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.712 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 241.16it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 48.556 - val loss: 1.395 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 102/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21.2s - loss: 1.549 - acc: 56.250: 100%|██████████| 3600/3600 [00:21<00:00, 169.83it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.341 - train acc: 47.944 - val loss: 1.355 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 103/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.533 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 231.51it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.333 - val loss: 1.366 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 104/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.0s - loss: 1.541 - acc: 37.500: 100%|██████████| 3600/3600 [00:16<00:00, 224.35it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.324 - train acc: 48.194 - val loss: 1.427 - val acc: 39.000 - val err: 61.000\n",
      "\n",
      "Epoch: 105/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.3s - loss: 1.402 - acc: 50.000: 100%|██████████| 3600/3600 [00:16<00:00, 220.22it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.325 - train acc: 49.833 - val loss: 1.394 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 106/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17.4s - loss: 1.084 - acc: 56.250: 100%|██████████| 3600/3600 [00:17<00:00, 207.20it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.315 - train acc: 48.944 - val loss: 1.397 - val acc: 44.000 - val err: 56.000\n",
      "\n",
      "Epoch: 107/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.9s - loss: 1.651 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 226.95it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.324 - train acc: 48.111 - val loss: 1.382 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 108/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.321 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 235.95it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 47.361 - val loss: 1.374 - val acc: 49.500 - val err: 50.500 [*]\n",
      "\n",
      "Epoch: 109/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.530 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 234.91it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 49.083 - val loss: 1.363 - val acc: 47.750 - val err: 52.250\n",
      "\n",
      "Epoch: 110/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.237 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 235.11it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.338 - train acc: 46.889 - val loss: 1.421 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 111/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.100 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.95it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 48.833 - val loss: 1.386 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 112/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.492 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.40it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.348 - train acc: 47.583 - val loss: 1.373 - val acc: 47.750 - val err: 52.250\n",
      "\n",
      "Epoch: 113/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.411 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 240.33it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 47.694 - val loss: 1.470 - val acc: 41.500 - val err: 58.500\n",
      "\n",
      "Epoch: 114/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.9s - loss: 1.539 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 226.38it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.324 - train acc: 48.250 - val loss: 1.380 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 115/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.362 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.62it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.324 - train acc: 48.278 - val loss: 1.322 - val acc: 50.250 - val err: 49.750 [*]\n",
      "\n",
      "Epoch: 116/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.366 - acc: 31.250: 100%|██████████| 3600/3600 [00:14<00:00, 240.52it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.316 - train acc: 49.222 - val loss: 1.349 - val acc: 49.250 - val err: 50.750\n",
      "\n",
      "Epoch: 117/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.382 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 240.96it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 48.417 - val loss: 1.375 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 118/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.4s - loss: 1.288 - acc: 50.000: 100%|██████████| 3600/3600 [00:16<00:00, 219.94it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 49.250 - val loss: 1.411 - val acc: 42.000 - val err: 58.000\n",
      "\n",
      "Epoch: 119/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.131 - acc: 75.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.11it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 47.889 - val loss: 1.373 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 120/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.515 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.55it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 48.167 - val loss: 1.354 - val acc: 49.250 - val err: 50.750\n",
      "\n",
      "Epoch: 121/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.288 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 235.75it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 48.250 - val loss: 1.442 - val acc: 42.500 - val err: 57.500\n",
      "\n",
      "Epoch: 122/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.601 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 237.61it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 47.972 - val loss: 1.362 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 123/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.272 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.326 - train acc: 47.917 - val loss: 1.399 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 124/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.481 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 240.67it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.315 - train acc: 48.389 - val loss: 1.421 - val acc: 42.500 - val err: 57.500\n",
      "\n",
      "Epoch: 125/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.304 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.63it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 49.528 - val loss: 1.336 - val acc: 47.000 - val err: 53.000\n",
      "\n",
      "Epoch: 126/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.429 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 241.35it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.324 - train acc: 48.861 - val loss: 1.378 - val acc: 47.500 - val err: 52.500\n",
      "\n",
      "Epoch: 127/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.494 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 240.45it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.306 - train acc: 49.694 - val loss: 1.413 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 128/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.545 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.08it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 49.556 - val loss: 1.390 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 129/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.377 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 230.28it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 48.139 - val loss: 1.377 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 130/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.583 - acc: 18.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.74it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 47.917 - val loss: 1.363 - val acc: 47.500 - val err: 52.500\n",
      "\n",
      "Epoch: 131/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22.1s - loss: 1.456 - acc: 43.750: 100%|██████████| 3600/3600 [00:22<00:00, 162.78it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.335 - train acc: 48.000 - val loss: 1.372 - val acc: 49.500 - val err: 50.500\n",
      "\n",
      "Epoch: 132/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19.5s - loss: 1.667 - acc: 25.000: 100%|██████████| 3600/3600 [00:19<00:00, 184.16it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.313 - train acc: 49.333 - val loss: 1.386 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 133/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.467 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.54it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 48.500 - val loss: 1.440 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 134/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.300 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.324 - train acc: 49.139 - val loss: 1.397 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 135/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.499 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.59it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.310 - train acc: 49.194 - val loss: 1.382 - val acc: 42.500 - val err: 57.500\n",
      "\n",
      "Epoch: 136/500 - LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.711 - acc: 18.750: 100%|██████████| 3600/3600 [00:15<00:00, 235.87it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 48.778 - val loss: 1.336 - val acc: 47.750 - val err: 52.250\n",
      "\n",
      "Epoch: 137/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.089 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.52it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 47.889 - val loss: 1.346 - val acc: 48.250 - val err: 51.750\n",
      "\n",
      "Epoch: 138/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.154 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.94it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.300 - train acc: 50.583 - val loss: 1.383 - val acc: 47.500 - val err: 52.500\n",
      "\n",
      "Epoch: 139/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.215 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 235.45it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.326 - train acc: 48.278 - val loss: 1.381 - val acc: 47.750 - val err: 52.250\n",
      "\n",
      "Epoch: 140/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.316 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 240.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 49.056 - val loss: 1.374 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 141/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.563 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 239.56it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 49.778 - val loss: 1.375 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 142/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.880 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.86it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 49.611 - val loss: 1.389 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 143/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.154 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 236.11it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 48.944 - val loss: 1.405 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 144/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.538 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 240.48it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.325 - train acc: 49.278 - val loss: 1.438 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 145/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.213 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 237.93it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.326 - train acc: 48.389 - val loss: 1.309 - val acc: 48.250 - val err: 51.750\n",
      "\n",
      "Epoch: 146/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.188 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 238.52it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.308 - train acc: 49.139 - val loss: 1.378 - val acc: 42.500 - val err: 57.500\n",
      "\n",
      "Epoch: 147/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.266 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 235.03it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 49.278 - val loss: 1.454 - val acc: 41.500 - val err: 58.500\n",
      "\n",
      "Epoch: 148/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.479 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 241.30it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 49.500 - val loss: 1.383 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 149/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 0.949 - acc: 75.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.85it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 48.417 - val loss: 1.395 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 150/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.030 - acc: 75.000: 100%|██████████| 3600/3600 [00:14<00:00, 241.33it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.330 - train acc: 48.722 - val loss: 1.390 - val acc: 47.000 - val err: 53.000\n",
      "\n",
      "Epoch: 151/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.9s - loss: 1.549 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 226.54it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.309 - train acc: 49.722 - val loss: 1.379 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 152/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.177 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.87it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.330 - train acc: 48.639 - val loss: 1.388 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 153/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.607 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 240.45it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.316 - train acc: 49.139 - val loss: 1.379 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 154/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.174 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 231.30it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 49.306 - val loss: 1.376 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 155/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.7s - loss: 1.463 - acc: 43.750: 100%|██████████| 3600/3600 [00:16<00:00, 215.79it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.311 - train acc: 48.750 - val loss: 1.384 - val acc: 47.000 - val err: 53.000\n",
      "\n",
      "Epoch: 156/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.179 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.27it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 49.806 - val loss: 1.383 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 157/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.514 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.47it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 48.222 - val loss: 1.367 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 158/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.8s - loss: 1.577 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 227.80it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 49.250 - val loss: 1.405 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 159/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.416 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.42it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 48.778 - val loss: 1.388 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 160/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.390 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.19it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 49.000 - val loss: 1.330 - val acc: 49.500 - val err: 50.500\n",
      "\n",
      "Epoch: 161/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.313 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 239.22it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.338 - train acc: 47.222 - val loss: 1.391 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 162/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.197 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 237.91it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 48.583 - val loss: 1.340 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 163/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.319 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.10it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.389 - val loss: 1.388 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 164/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.8s - loss: 1.218 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 228.28it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.316 - train acc: 49.111 - val loss: 1.368 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 165/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.330 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 237.32it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.325 - train acc: 48.917 - val loss: 1.376 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 166/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.424 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.60it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 47.722 - val loss: 1.362 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 167/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.335 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 236.77it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 48.556 - val loss: 1.359 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 168/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.252 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 238.64it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.310 - train acc: 49.222 - val loss: 1.410 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 169/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.113 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.87it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 49.389 - val loss: 1.394 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 170/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.192 - acc: 56.250: 100%|██████████| 3600/3600 [00:14<00:00, 240.41it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.335 - train acc: 48.278 - val loss: 1.387 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 171/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.608 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.12it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 48.889 - val loss: 1.368 - val acc: 49.250 - val err: 50.750\n",
      "\n",
      "Epoch: 172/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.931 - acc: 18.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.59it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.333 - train acc: 49.083 - val loss: 1.383 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 173/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.600 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 234.56it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.303 - train acc: 49.389 - val loss: 1.397 - val acc: 44.000 - val err: 56.000\n",
      "\n",
      "Epoch: 174/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.216 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.06it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.333 - train acc: 48.444 - val loss: 1.391 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 175/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.100 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.50it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.330 - train acc: 49.417 - val loss: 1.414 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 176/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.208 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.74it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.315 - train acc: 49.444 - val loss: 1.343 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 177/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.395 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.12it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.139 - val loss: 1.400 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 178/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.233 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.55it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.306 - val loss: 1.371 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 179/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.339 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.42it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.338 - train acc: 48.278 - val loss: 1.430 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 180/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.421 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 235.77it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.334 - train acc: 48.417 - val loss: 1.348 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 181/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.367 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.13it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 48.528 - val loss: 1.361 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 182/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.697 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.67it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 49.472 - val loss: 1.380 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 183/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.256 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 236.63it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 48.500 - val loss: 1.437 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 184/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17.4s - loss: 1.248 - acc: 50.000: 100%|██████████| 3600/3600 [00:17<00:00, 206.44it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.313 - train acc: 49.806 - val loss: 1.362 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 185/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.227 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.53it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.335 - train acc: 48.278 - val loss: 1.414 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 186/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.485 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.11it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.389 - val loss: 1.375 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 187/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.508 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.49it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.311 - train acc: 50.389 - val loss: 1.345 - val acc: 51.250 - val err: 48.750 [*]\n",
      "\n",
      "Epoch: 188/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23.0s - loss: 1.582 - acc: 43.750: 100%|██████████| 3600/3600 [00:22<00:00, 156.72it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 49.278 - val loss: 1.361 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 189/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.5s - loss: 1.814 - acc: 37.500: 100%|██████████| 3600/3600 [00:16<00:00, 218.46it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 49.444 - val loss: 1.390 - val acc: 47.000 - val err: 53.000\n",
      "\n",
      "Epoch: 190/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.2s - loss: 1.298 - acc: 68.750: 100%|██████████| 3600/3600 [00:16<00:00, 221.88it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.334 - train acc: 48.361 - val loss: 1.384 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 191/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.1s - loss: 1.216 - acc: 56.250: 100%|██████████| 3600/3600 [00:16<00:00, 223.78it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.306 - train acc: 48.611 - val loss: 1.389 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 192/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.3s - loss: 1.614 - acc: 37.500: 100%|██████████| 3600/3600 [00:16<00:00, 220.48it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 49.167 - val loss: 1.406 - val acc: 42.500 - val err: 57.500\n",
      "\n",
      "Epoch: 193/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17.3s - loss: 1.524 - acc: 43.750: 100%|██████████| 3600/3600 [00:17<00:00, 207.89it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.278 - val loss: 1.388 - val acc: 41.750 - val err: 58.250\n",
      "\n",
      "Epoch: 194/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.756 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 230.94it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 49.056 - val loss: 1.340 - val acc: 47.000 - val err: 53.000\n",
      "\n",
      "Epoch: 195/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.392 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 234.32it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 48.639 - val loss: 1.352 - val acc: 47.000 - val err: 53.000\n",
      "\n",
      "Epoch: 196/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.338 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 234.59it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 49.611 - val loss: 1.330 - val acc: 47.750 - val err: 52.250\n",
      "\n",
      "Epoch: 197/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.812 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.12it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.330 - train acc: 48.000 - val loss: 1.359 - val acc: 48.250 - val err: 51.750\n",
      "\n",
      "Epoch: 198/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.405 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.22it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.028 - val loss: 1.420 - val acc: 41.500 - val err: 58.500\n",
      "\n",
      "Epoch: 199/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.443 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 49.667 - val loss: 1.351 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 200/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 0.976 - acc: 81.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.68it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 50.000 - val loss: 1.368 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 201/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 0.948 - acc: 81.250: 100%|██████████| 3600/3600 [00:14<00:00, 240.30it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 49.056 - val loss: 1.419 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 202/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.549 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 235.12it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 49.083 - val loss: 1.396 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 203/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.146 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.01it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.334 - train acc: 48.361 - val loss: 1.410 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 204/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.8s - loss: 1.315 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 227.82it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.315 - train acc: 48.778 - val loss: 1.364 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 205/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.675 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.02it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 47.972 - val loss: 1.352 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 206/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.541 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 230.62it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.324 - train acc: 49.250 - val loss: 1.398 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 207/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25.6s - loss: 1.360 - acc: 68.750: 100%|██████████| 3600/3600 [00:25<00:00, 140.83it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 48.028 - val loss: 1.376 - val acc: 47.500 - val err: 52.500\n",
      "\n",
      "Epoch: 208/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.9s - loss: 1.228 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 226.47it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 48.861 - val loss: 1.396 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 209/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.7s - loss: 1.148 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 228.98it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 48.583 - val loss: 1.414 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 210/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.326 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 237.65it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.342 - train acc: 47.500 - val loss: 1.354 - val acc: 49.000 - val err: 51.000\n",
      "\n",
      "Epoch: 211/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.382 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 240.00it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 48.111 - val loss: 1.352 - val acc: 49.500 - val err: 50.500\n",
      "\n",
      "Epoch: 212/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.272 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.89it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 49.611 - val loss: 1.384 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 213/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.098 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.98it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.313 - train acc: 49.806 - val loss: 1.372 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 214/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.221 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 238.81it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 48.250 - val loss: 1.405 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 215/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.346 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 240.98it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 49.528 - val loss: 1.405 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 216/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.252 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 235.03it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.324 - train acc: 48.722 - val loss: 1.359 - val acc: 48.750 - val err: 51.250\n",
      "\n",
      "Epoch: 217/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.938 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 240.61it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.311 - train acc: 49.222 - val loss: 1.397 - val acc: 48.250 - val err: 51.750\n",
      "\n",
      "Epoch: 218/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.182 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.73it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.337 - train acc: 47.528 - val loss: 1.404 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 219/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.585 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.39it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 49.111 - val loss: 1.392 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 220/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.572 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.56it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.313 - train acc: 48.611 - val loss: 1.387 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 221/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.753 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.13it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.307 - train acc: 49.361 - val loss: 1.388 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 222/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.418 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.57it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 48.333 - val loss: 1.409 - val acc: 47.500 - val err: 52.500\n",
      "\n",
      "Epoch: 223/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.516 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.31it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.321 - train acc: 48.500 - val loss: 1.369 - val acc: 47.500 - val err: 52.500\n",
      "\n",
      "Epoch: 224/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.592 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 231.12it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.222 - val loss: 1.431 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 225/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.539 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 234.36it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 49.278 - val loss: 1.361 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 226/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.468 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.97it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.312 - train acc: 48.667 - val loss: 1.383 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 227/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.148 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 236.50it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 48.056 - val loss: 1.352 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 228/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.411 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.85it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 48.389 - val loss: 1.389 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 229/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.205 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 236.51it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 49.528 - val loss: 1.402 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 230/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.560 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.26it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.325 - train acc: 48.778 - val loss: 1.349 - val acc: 46.250 - val err: 53.750\n",
      "\n",
      "Epoch: 231/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.493 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 234.40it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 48.694 - val loss: 1.337 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 232/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.286 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 235.55it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.336 - train acc: 48.667 - val loss: 1.392 - val acc: 47.000 - val err: 53.000\n",
      "\n",
      "Epoch: 233/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.251 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.70it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.338 - train acc: 47.222 - val loss: 1.359 - val acc: 47.750 - val err: 52.250\n",
      "\n",
      "Epoch: 234/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.206 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.12it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 49.111 - val loss: 1.369 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 235/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.594 - acc: 75.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.335 - train acc: 48.500 - val loss: 1.354 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 236/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.401 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.22it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.321 - train acc: 48.556 - val loss: 1.341 - val acc: 49.250 - val err: 50.750\n",
      "\n",
      "Epoch: 237/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.447 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.52it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.444 - val loss: 1.391 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 238/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.0s - loss: 1.379 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 225.47it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.334 - train acc: 47.306 - val loss: 1.433 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 239/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.359 - acc: 50.000: 100%|██████████| 3600/3600 [00:14<00:00, 242.14it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.500 - val loss: 1.368 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 240/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 0.979 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.53it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 47.806 - val loss: 1.337 - val acc: 46.250 - val err: 53.750\n",
      "\n",
      "Epoch: 241/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.500 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.81it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 48.167 - val loss: 1.361 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 242/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.405 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.45it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.315 - train acc: 49.528 - val loss: 1.395 - val acc: 44.000 - val err: 56.000\n",
      "\n",
      "Epoch: 243/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.390 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.80it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.316 - train acc: 48.417 - val loss: 1.401 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 244/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.428 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 239.21it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.325 - train acc: 49.417 - val loss: 1.354 - val acc: 48.750 - val err: 51.250\n",
      "\n",
      "Epoch: 245/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.507 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.85it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.250 - val loss: 1.354 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 246/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.072 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 232.71it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.313 - train acc: 49.417 - val loss: 1.378 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 247/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.143 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.96it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.334 - train acc: 48.917 - val loss: 1.354 - val acc: 49.750 - val err: 50.250\n",
      "\n",
      "Epoch: 248/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.238 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.26it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 48.806 - val loss: 1.334 - val acc: 48.250 - val err: 51.750\n",
      "\n",
      "Epoch: 249/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.503 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 235.33it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 48.833 - val loss: 1.384 - val acc: 42.500 - val err: 57.500\n",
      "\n",
      "Epoch: 250/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.570 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.64it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 47.833 - val loss: 1.385 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 251/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.693 - acc: 18.750: 100%|██████████| 3600/3600 [00:14<00:00, 241.11it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 48.667 - val loss: 1.377 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 252/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.219 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.55it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.341 - train acc: 47.583 - val loss: 1.376 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 253/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.448 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 233.29it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 48.028 - val loss: 1.366 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 254/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.462 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 236.77it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.336 - train acc: 47.472 - val loss: 1.399 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 255/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.414 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 235.51it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.316 - train acc: 48.750 - val loss: 1.388 - val acc: 46.250 - val err: 53.750\n",
      "\n",
      "Epoch: 256/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19.6s - loss: 1.673 - acc: 31.250: 100%|██████████| 3600/3600 [00:19<00:00, 183.80it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.330 - train acc: 49.000 - val loss: 1.366 - val acc: 48.500 - val err: 51.500\n",
      "\n",
      "Epoch: 257/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.8s - loss: 1.372 - acc: 50.000: 100%|██████████| 3600/3600 [00:16<00:00, 213.85it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.316 - train acc: 49.278 - val loss: 1.400 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 258/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.2s - loss: 1.569 - acc: 31.250: 100%|██████████| 3600/3600 [00:16<00:00, 222.51it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 47.528 - val loss: 1.323 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 259/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.4s - loss: 1.713 - acc: 31.250: 100%|██████████| 3600/3600 [00:16<00:00, 219.74it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.556 - val loss: 1.401 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 260/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17.4s - loss: 1.424 - acc: 37.500: 100%|██████████| 3600/3600 [00:17<00:00, 206.45it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.309 - train acc: 48.944 - val loss: 1.388 - val acc: 48.250 - val err: 51.750\n",
      "\n",
      "Epoch: 261/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.439 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 233.23it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.305 - train acc: 50.750 - val loss: 1.427 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 262/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.381 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 234.73it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.315 - train acc: 49.611 - val loss: 1.329 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 263/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.316 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 236.68it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.326 - train acc: 48.528 - val loss: 1.403 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 264/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.453 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.18it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 47.583 - val loss: 1.392 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 265/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.526 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 235.73it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.330 - train acc: 48.722 - val loss: 1.369 - val acc: 48.000 - val err: 52.000\n",
      "\n",
      "Epoch: 266/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.7s - loss: 1.325 - acc: 56.250: 100%|██████████| 3600/3600 [00:16<00:00, 216.03it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.316 - train acc: 49.167 - val loss: 1.389 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 267/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.589 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 236.41it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.343 - train acc: 47.722 - val loss: 1.358 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 268/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.213 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.62it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 49.056 - val loss: 1.414 - val acc: 42.250 - val err: 57.750\n",
      "\n",
      "Epoch: 269/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.793 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 234.30it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 50.028 - val loss: 1.377 - val acc: 47.500 - val err: 52.500\n",
      "\n",
      "Epoch: 270/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.224 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.39it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.310 - train acc: 49.194 - val loss: 1.381 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 271/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.659 - acc: 18.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.23it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 49.306 - val loss: 1.377 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 272/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.079 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.21it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.308 - train acc: 49.722 - val loss: 1.344 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 273/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.211 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 234.16it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 48.306 - val loss: 1.375 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 274/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.413 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 232.36it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 48.306 - val loss: 1.412 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 275/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.6s - loss: 1.417 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 231.24it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 48.306 - val loss: 1.359 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 276/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.089 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.03it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.319 - train acc: 49.000 - val loss: 1.378 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 277/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.707 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.40it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 48.333 - val loss: 1.411 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 278/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.344 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.99it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.312 - train acc: 50.417 - val loss: 1.405 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 279/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.549 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.01it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.330 - train acc: 47.833 - val loss: 1.392 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 280/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24.1s - loss: 1.122 - acc: 50.000: 100%|██████████| 3600/3600 [00:24<00:00, 149.18it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 47.583 - val loss: 1.364 - val acc: 43.250 - val err: 56.750\n",
      "\n",
      "Epoch: 281/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18.1s - loss: 1.158 - acc: 62.500: 100%|██████████| 3600/3600 [00:18<00:00, 199.39it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.315 - train acc: 48.556 - val loss: 1.394 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 282/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.455 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 232.47it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.307 - train acc: 48.500 - val loss: 1.351 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 283/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.9s - loss: 1.412 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 226.31it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 47.944 - val loss: 1.444 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 284/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 0.910 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 235.96it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 49.167 - val loss: 1.383 - val acc: 43.750 - val err: 56.250\n",
      "\n",
      "Epoch: 285/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.901 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.82it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.528 - val loss: 1.361 - val acc: 48.000 - val err: 52.000\n",
      "\n",
      "Epoch: 286/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.068 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.07it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.309 - train acc: 49.278 - val loss: 1.370 - val acc: 48.750 - val err: 51.250\n",
      "\n",
      "Epoch: 287/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16.3s - loss: 1.598 - acc: 37.500: 100%|██████████| 3600/3600 [00:16<00:00, 221.08it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.321 - train acc: 48.250 - val loss: 1.383 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 288/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.695 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.66it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.326 - train acc: 48.472 - val loss: 1.433 - val acc: 43.000 - val err: 57.000\n",
      "\n",
      "Epoch: 289/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.157 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 232.94it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.310 - train acc: 48.611 - val loss: 1.360 - val acc: 48.250 - val err: 51.750\n",
      "\n",
      "Epoch: 290/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.516 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.19it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 49.111 - val loss: 1.375 - val acc: 48.500 - val err: 51.500\n",
      "\n",
      "Epoch: 291/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.408 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 234.51it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 48.694 - val loss: 1.383 - val acc: 46.250 - val err: 53.750\n",
      "\n",
      "Epoch: 292/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.218 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 235.80it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.310 - train acc: 49.111 - val loss: 1.378 - val acc: 50.000 - val err: 50.000\n",
      "\n",
      "Epoch: 293/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.413 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 236.34it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 48.111 - val loss: 1.396 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 294/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.462 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.80it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 48.750 - val loss: 1.394 - val acc: 45.250 - val err: 54.750\n",
      "\n",
      "Epoch: 295/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.065 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 235.89it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 48.889 - val loss: 1.309 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 296/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.612 - acc: 31.250: 100%|██████████| 3600/3600 [00:15<00:00, 235.39it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.306 - val loss: 1.351 - val acc: 47.000 - val err: 53.000\n",
      "\n",
      "Epoch: 297/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.260 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 238.18it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.330 - train acc: 48.417 - val loss: 1.414 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 298/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.474 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 236.89it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.326 - train acc: 48.083 - val loss: 1.422 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 299/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.084 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.16it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.334 - train acc: 49.056 - val loss: 1.376 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 300/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.295 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.31it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.335 - train acc: 48.167 - val loss: 1.395 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 301/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.356 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.55it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 48.861 - val loss: 1.374 - val acc: 46.250 - val err: 53.750\n",
      "\n",
      "Epoch: 302/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.374 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.45it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 49.028 - val loss: 1.407 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 303/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.270 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 235.46it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.194 - val loss: 1.386 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 304/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.349 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.22it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.328 - train acc: 48.389 - val loss: 1.397 - val acc: 42.500 - val err: 57.500\n",
      "\n",
      "Epoch: 305/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.286 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 236.50it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.343 - train acc: 48.028 - val loss: 1.369 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 306/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.260 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.91it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 47.583 - val loss: 1.370 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 307/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.676 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 232.81it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 49.000 - val loss: 1.393 - val acc: 44.500 - val err: 55.500\n",
      "\n",
      "Epoch: 308/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.664 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 233.47it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.311 - train acc: 48.778 - val loss: 1.436 - val acc: 43.000 - val err: 57.000\n",
      "\n",
      "Epoch: 309/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.187 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 234.47it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.321 - train acc: 49.833 - val loss: 1.338 - val acc: 49.000 - val err: 51.000\n",
      "\n",
      "Epoch: 310/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.392 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 235.60it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.332 - train acc: 48.722 - val loss: 1.415 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 311/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.9s - loss: 1.207 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 226.13it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.322 - train acc: 49.417 - val loss: 1.367 - val acc: 47.750 - val err: 52.250\n",
      "\n",
      "Epoch: 312/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.235 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 238.78it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.325 - train acc: 48.389 - val loss: 1.359 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 313/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.012 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 235.85it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 48.056 - val loss: 1.384 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 314/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.199 - acc: 62.500: 100%|██████████| 3600/3600 [00:14<00:00, 240.51it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.325 - train acc: 49.194 - val loss: 1.384 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 315/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.019 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 238.17it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 48.444 - val loss: 1.388 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 316/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.873 - acc: 18.750: 100%|██████████| 3600/3600 [00:15<00:00, 237.76it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 47.556 - val loss: 1.373 - val acc: 44.750 - val err: 55.250\n",
      "\n",
      "Epoch: 317/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.225 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.94it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.321 - train acc: 49.139 - val loss: 1.440 - val acc: 41.750 - val err: 58.250\n",
      "\n",
      "Epoch: 318/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.271 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 236.82it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 49.944 - val loss: 1.437 - val acc: 40.500 - val err: 59.500\n",
      "\n",
      "Epoch: 319/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.379 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 234.80it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.320 - train acc: 47.667 - val loss: 1.385 - val acc: 45.500 - val err: 54.500\n",
      "\n",
      "Epoch: 320/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.418 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.06it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.314 - train acc: 49.028 - val loss: 1.395 - val acc: 48.500 - val err: 51.500\n",
      "\n",
      "Epoch: 321/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.6s - loss: 1.343 - acc: 43.750: 100%|██████████| 3600/3600 [00:14<00:00, 246.34it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.312 - train acc: 49.611 - val loss: 1.336 - val acc: 48.750 - val err: 51.250\n",
      "\n",
      "Epoch: 322/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.3s - loss: 1.271 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 235.90it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 47.667 - val loss: 1.419 - val acc: 42.750 - val err: 57.250\n",
      "\n",
      "Epoch: 323/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.423 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 231.83it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.326 - train acc: 48.722 - val loss: 1.377 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 324/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.320 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 233.09it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.318 - train acc: 49.306 - val loss: 1.428 - val acc: 43.500 - val err: 56.500\n",
      "\n",
      "Epoch: 325/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.495 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.61it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.321 - train acc: 49.528 - val loss: 1.348 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 326/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.551 - acc: 43.750: 100%|██████████| 3600/3600 [00:15<00:00, 233.68it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.312 - train acc: 49.778 - val loss: 1.362 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 327/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.4s - loss: 1.433 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 233.46it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 48.500 - val loss: 1.395 - val acc: 46.750 - val err: 53.250\n",
      "\n",
      "Epoch: 328/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.9s - loss: 1.477 - acc: 37.500: 100%|██████████| 3600/3600 [00:14<00:00, 242.15it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 48.750 - val loss: 1.377 - val acc: 47.500 - val err: 52.500\n",
      "\n",
      "Epoch: 329/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.454 - acc: 25.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.23it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.336 - train acc: 48.444 - val loss: 1.347 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 330/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.309 - acc: 62.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.54it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.323 - train acc: 48.833 - val loss: 1.347 - val acc: 45.000 - val err: 55.000\n",
      "\n",
      "Epoch: 331/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.463 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.39it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 48.000 - val loss: 1.373 - val acc: 48.000 - val err: 52.000\n",
      "\n",
      "Epoch: 332/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.585 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 238.44it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.339 - train acc: 48.861 - val loss: 1.400 - val acc: 44.250 - val err: 55.750\n",
      "\n",
      "Epoch: 333/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.1s - loss: 1.670 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 237.71it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.326 - train acc: 48.222 - val loss: 1.365 - val acc: 46.500 - val err: 53.500\n",
      "\n",
      "Epoch: 334/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.5s - loss: 1.165 - acc: 68.750: 100%|██████████| 3600/3600 [00:15<00:00, 232.46it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.317 - train acc: 48.944 - val loss: 1.401 - val acc: 47.250 - val err: 52.750\n",
      "\n",
      "Epoch: 335/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.2s - loss: 1.550 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 237.21it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.316 - train acc: 50.000 - val loss: 1.420 - val acc: 43.000 - val err: 57.000\n",
      "\n",
      "Epoch: 336/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.313 - acc: 56.250: 100%|██████████| 3600/3600 [00:15<00:00, 239.26it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.331 - train acc: 47.694 - val loss: 1.351 - val acc: 46.000 - val err: 54.000\n",
      "\n",
      "Epoch: 337/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.320 - acc: 37.500: 100%|██████████| 3600/3600 [00:15<00:00, 239.51it/s]\n",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.327 - train acc: 48.917 - val loss: 1.363 - val acc: 45.750 - val err: 54.250\n",
      "\n",
      "Epoch: 338/500 - LR: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.0s - loss: 1.176 - acc: 50.000: 100%|██████████| 3600/3600 [00:15<00:00, 239.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.329 - train acc: 48.611 - val loss: 1.376 - val acc: 42.500 - val err: 57.500\n",
      "[!] No improvement in a while, stopping training.\n"
     ]
    }
   ],
   "source": [
    "main(global_config)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "plot_dir = \"./plots/\" + global_config.model_name + \"/\"\n",
    "epoch = 1\n",
    "\n",
    "\n",
    "# read in pickle files\n",
    "glimpses = pickle.load(open(plot_dir + \"g_{}.p\".format(epoch), \"rb\"))\n",
    "locations = pickle.load(open(plot_dir + \"l_{}.p\".format(epoch), \"rb\"))\n",
    "\n",
    "glimpses = np.concatenate(glimpses)\n",
    "\n",
    "# grab useful params\n",
    "size = int(plot_dir.split(\"_\")[2].split(\"x\")[0])\n",
    "num_anims = len(locations)\n",
    "num_cols = glimpses.shape[0]\n",
    "img_shape = glimpses.shape[1]\n",
    "\n",
    "# denormalize coordinates\n",
    "coords = [denormalize(img_shape, l) for l in locations]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=num_cols)\n",
    "\n",
    "\n",
    "fig.set_dpi(100)\n",
    "\n",
    "# plot base image\n",
    "for j, ax in enumerate(axs.flat):\n",
    "    ax.imshow(glimpses[j], cmap=\"Greys_r\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "def updateData(i):\n",
    "    color = \"r\"\n",
    "    co = coords[i]\n",
    "    for j, ax in enumerate(axs.flat):\n",
    "        for p in ax.patches:\n",
    "            p.remove()\n",
    "        c = co[j]\n",
    "        rect = bounding_box(c[0], c[1], size, color)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "# animate\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, updateData, frames=num_anims, interval=500, repeat=True\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import HTML\n",
    "HTML(anim.to_html5_video()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#inp = torch.arange(60*60*5.0).reshape(5,1,60,60)\n",
    "#locs = torch.zeros((5,2))\n",
    "#inp = torch.ones((5,1,60,60))\n",
    "#locs = torch.zeros((5,2))\n",
    "#GlimpseNetwork(100,50,12,2,4,1).forward(inp, locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locator.dataset_dict[DatasetType.TEST].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = locator.data_loader(DatasetType.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading model from ./ckpt\n",
      "[*] Loaded ram_10_8x8_8_model_best.pth.tar checkpoint @ epoch 187 with best valid acc of 51.250\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'test_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-189d49efe13a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#c = np.sum(locator.dataset_dict[DatasetType.TEST].labels == predictions)/2000 should be same as acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dv3c/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-1def1a6e451d>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'test_loader'"
     ]
    }
   ],
   "source": [
    "\n",
    "prepare_dirs(global_config)\n",
    "\n",
    "# instantiate data loaders\n",
    "if global_config.is_train:\n",
    "    train_loader = locator.data_loader(DatasetType.TRAIN)\n",
    "    valid_loader = locator.data_loader(DatasetType.VALID)\n",
    "    dloader = (train_loader,valid_loader)\n",
    "else:\n",
    "    dloader = locator.data_loader(DatasetType.TEST)\n",
    "\n",
    "trainer = Trainer(global_config, dloader)\n",
    "predictions = trainer.test()\n",
    "predictions = np.vstack([p.numpy() for p in predictions]).flatten()\n",
    "#c = np.sum(locator.dataset_dict[DatasetType.TEST].labels == predictions)/2000 should be same as acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = locator.dataset_dict[DatasetType.TEST].data\n",
    "labels = locator.dataset_dict[DatasetType.TEST].labels\n",
    "source_images = locator.dataset_dict[DatasetType.TEST].source_images\n",
    "correct = labels == predictions\n",
    "correct_counts = np.bincount(labels[correct])\n",
    "\n",
    "wrong = labels != predictions\n",
    "wrong_counts = np.bincount(labels[wrong])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_labels = ['0', '1', '2', '3+']\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(class_labels, correct_counts, width, label='Correct',color =\"b\")\n",
    "ax.bar(class_labels, wrong_counts, width, bottom=correct_counts,\n",
    "       label='Wrong', color=\"r\")\n",
    "\n",
    "ax.set_ylabel('N')\n",
    "ax.set_title('Predictions per number of cells (classes)')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def show_big(i):\n",
    "    fig, axes = plt.subplots(1,1,figsize=(25,25) )\n",
    "    axes.imshow(data[i][0], cmap=plt.cm.gray)\n",
    "    axes.set_title(labels[i])\n",
    "    \n",
    "def show_one(i):\n",
    "    sis = source_images[i]\n",
    "    n_sis = sis.shape[0]\n",
    "    if(n_sis == 0):        \n",
    "        plt.imshow(data[i][0], cmap=plt.cm.gray)\n",
    "        plt.title(labels[i])\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1,n_sis+1,figsize=(25,25) )\n",
    "        axes[0].imshow(data[i][0], cmap=plt.cm.gray)\n",
    "        axes[0].set_title(labels[i])\n",
    "        for i, si in enumerate(sis):\n",
    "            axes[i+1].imshow(si[0], cmap=plt.cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show_big(997)\n",
    "show_one(997)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
